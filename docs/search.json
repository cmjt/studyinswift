[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Colours of the Taylor Swift Universe",
    "section": "",
    "text": "Taylor Swift’s Eras Tour Color-Music Relationships\nThis is a short collection of visualization and Rstats exercises exploring Taylor Swift’s use of colour in her Eras tour outfits and her lyrics!"
  },
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "1  Data wrangling",
    "section": "",
    "text": "Note\n\n\n\nAll data paths are relative to the root of the GitHub repository\n\n\n\n## packages \nrequire(tidyverse)\nrequire(readxl)\n\n\n## reading in data\nsurpriseSongsDressColours <-  readxl::read_excel(\"raw_data/surprise_songs.xlsx\", sheet = \"List\")\nsurpriseSongsDressColours$Date <- as.Date(surpriseSongsDressColours$Date)\n## map hex colour to outfit\ndressColorMapping <- unique(surpriseSongsDressColours %>% select(DressName, ColourHex1))\ncolorPaletteDresses <- setNames(dressColorMapping$ColourHex1, dressColorMapping$DressName)\npathToDressColours <- \"dress_images/images_high_res/cropped/\"\n\n\n## Need only consider first element of each concerts as the\n## same outfit was worn for all surprise songs\n## for anyone concert\noneRowPerConcert <- surpriseSongsDressColours %>%\n    group_by(Date) %>%\n    arrange(Date, Order) %>% \n    slice(1) %>%\n    ungroup()\noneRowPerConcert\n\n# A tibble: 147 × 26\n   `Song title`         Mashups Mashup Mashup2 Guest City  State Country Stadium\n   <chr>                <chr>   <chr>  <chr>   <chr> <chr> <chr> <chr>   <chr>  \n 1 mirrorball           None    <NA>   <NA>    <NA>  Glen… Ariz… US      State …\n 2 this is me trying    None    <NA>   <NA>    <NA>  Glen… Ariz… US      State …\n 3 Our Song             None    <NA>   <NA>    <NA>  Las … Neva… US      Allegi…\n 4 cowboy like me       None    <NA>   <NA>    Marc… Las … Neva… US      Allegi…\n 5 Sad Beautiful Tragic None    <NA>   <NA>    <NA>  Arli… Texas US      AT&T   \n 6 Death By A Thousand… None    <NA>   <NA>    <NA>  Arli… Texas US      AT&T   \n 7 Speak Now            None    <NA>   <NA>    <NA>  Tampa Flor… US      Raymon…\n 8 The Great War        None    <NA>   <NA>    Aaro… Tampa Flor… US      Raymon…\n 9 mad woman            None    <NA>   <NA>    <NA>  Tampa Flor… US      Raymon…\n10 Wonderland           None    <NA>   <NA>    <NA>  Hous… Texas US      NRG    \n# ℹ 137 more rows\n# ℹ 17 more variables: Date <date>, DressName <chr>, Legs <chr>,\n#   Relationship <chr>, Start <dttm>, End <dttm>, Colour1 <chr>,\n#   ColourHex1 <chr>, ColourRGB1 <chr>, Colour2 <chr>, ColourHex2 <chr>,\n#   ColourRGB2 <chr>, `Night #` <dbl>, Order <dbl>, Instrument <chr>,\n#   `Special Annoucement` <chr>, Notes <chr>\n\n\n\n## map outfits to the corresponding images\noneRowPerConcert %>%\n    count(DressName) %>%\n    mutate(\n        percentage = n / sum(n) * 100,\n        imagePath = case_when(\n            DressName == \"Pink\" ~paste0(pathToDressColours, \"pink.jpg\"),\n            DressName == \"Green\" ~paste0(pathToDressColours, \"green.jpg\"),\n            DressName == \"Yellow\" ~paste0(pathToDressColours, \"yellow.jpg\"),\n            DressName == \"Blue\" ~paste0(pathToDressColours, \"blue.jpg\"),\n            DressName == \"Flamingo pink\" ~ paste0(pathToDressColours,\"flamingo_pink.jpg\"),\n            DressName == \"Ocean blue\" ~ paste0(pathToDressColours,\"ocean_blue.jpg\"),\n            DressName == \"Sunset orange\" ~ paste0(pathToDressColours,\"sunset_orange.jpg\"),\n            DressName == \"Cotton candy\" ~paste0(pathToDressColours, \"cotton_candy.jpg\"),\n            DressName == \"Blurple\" ~paste0(pathToDressColours, \"blurple.jpg\"),\n            DressName == \"Grapefruit\" ~ paste0(pathToDressColours,\"grapefruit.jpg\"),\n            DressName == \"Popsicle\" ~ paste0(pathToDressColours,\"popsicle.jpg\"),\n            TRUE ~ NA_character_\n        )) -> outfits\noutfits\n\n# A tibble: 11 × 4\n   DressName         n percentage imagePath                                     \n   <chr>         <int>      <dbl> <chr>                                         \n 1 Blue              9       6.12 dress_images/images_high_res/cropped/blue.jpg \n 2 Blurple           7       4.76 dress_images/images_high_res/cropped/blurple.…\n 3 Cotton candy      3       2.04 dress_images/images_high_res/cropped/cotton_c…\n 4 Flamingo pink    15      10.2  dress_images/images_high_res/cropped/flamingo…\n 5 Grapefruit        3       2.04 dress_images/images_high_res/cropped/grapefru…\n 6 Green            20      13.6  dress_images/images_high_res/cropped/green.jpg\n 7 Ocean blue       14       9.52 dress_images/images_high_res/cropped/ocean_bl…\n 8 Pink             29      19.7  dress_images/images_high_res/cropped/pink.jpg \n 9 Popsicle          4       2.72 dress_images/images_high_res/cropped/popsicle…\n10 Sunset orange    20      13.6  dress_images/images_high_res/cropped/sunset_o…\n11 Yellow           23      15.6  dress_images/images_high_res/cropped/yellow.j…\n\n\n\nallSongsMetadata <- \"raw_data/album_info_metadata_neutral.xlsx\"\nallSongsMetadata <- readxl::read_excel(allSongsMetadata, sheet = \"metadata\")\nsource(\"code/colour_palletts.r\")\nrawColorData <- data.frame(\n    colour = trimws(unlist(strsplit(allSongsMetadata$colour_MK, \";\"))),\n    meaning = trimws(unlist(strsplit(allSongsMetadata$colour_meaningMK, \";\")))\n) %>% filter(!is.na(colour) & !is.na(meaning))\n\ncolorSentimentScores <- rawColorData %>%\n    mutate(\n        meaning = trimws(meaning),  \n        score = case_when(\n            tolower(meaning) == \"positive\" ~ 1,\n            tolower(meaning) == \"neutral\" ~ 0.5,\n            tolower(meaning) == \"negative\" ~ 0,\n            TRUE ~ NA_real_\n        )\n    )\n\n## Calculate average sentiment for each individual color\nindividualColorSentiments <- colorSentimentScores %>%\n    group_by(colour) %>%\n    summarise(\n        avgSentiment = mean(score, na.rm = TRUE),\n        mentionCount = n()\n    ) %>%\n    ungroup()\n\nindividualColorSentiments$colourGroup <- colorGroups[individualColorSentiments$colour]\nindividualColorSentiments$colourHexColour <-sapply(individualColorSentiments$colour, \\(x) colorPaletteColours[[x]])\nindividualColorSentiments$colourGroupColour <-sapply(individualColorSentiments$colourGroup, \\(x) colorPaletteGroups[[x]])\n\nindividualColorSentiments\n\n# A tibble: 69 × 6\n   colour                avgSentiment mentionCount colourGroup   colourHexColour\n   <chr>                        <dbl>        <int> <chr>         <chr>          \n 1 amber                        0.5              1 yellows       #FFBF00        \n 2 aquamarine                   1                1 blues         #7FFFD4        \n 3 aurora borealis green        1                2 greens        #78E08F        \n 4 black                        0.5              9 blacks        #000000        \n 5 black and white              0.25             4 black and wh… #C0C0C0        \n 6 blackout                     1                1 blacks        #1A1A1A        \n 7 bleached                     0.5              1 whites        #F5F5DC        \n 8 blood monlit                 1                1 reds          #8A0303        \n 9 blood-soaked                 0                2 reds          #8B0000        \n10 blue                         0.409           22 blues         #0000FF        \n# ℹ 59 more rows\n# ℹ 1 more variable: colourGroupColour <chr>"
  },
  {
    "objectID": "viz.html#the-most-worn-looks",
    "href": "viz.html#the-most-worn-looks",
    "title": "2  Visualizing surprise song outfits",
    "section": "The most worn looks",
    "text": "The most worn looks\n\n## barchart\nggplot(outfits, aes(x = reorder(DressName, -n), y = n, fill = DressName)) +\n    geom_bar(stat = \"identity\", width = 0.8) +  \n    geom_image(\n        aes(image = imagePath, y = n),  \n        size = 0.15,                    \n        by = \"height\"                    \n    ) +\n    geom_text(\n        aes(y = n + 3.8, label = paste0(n, \"\\n(\", round(percentage, 1), \"%)\")),  \n        vjust = 0,  \n        color = \"black\",\n        size = 4\n    ) +\n    scale_fill_manual(values = colorPaletteDresses) +\n    theme_minimal() +\n    labs(title = \"\", x = \"\", y = \"\") +\n    theme(\n        axis.text.x = element_text(angle = 45, hjust = 1, size = 14),\n        axis.text.y = element_text(size = 14),\n        plot.title = element_text(hjust = 0.5, size = 16),\n        axis.title.x = element_blank(),\n        axis.title.y = element_blank(),\n        legend.position = \"none\"\n    ) + ylim(0, 35)"
  },
  {
    "objectID": "viz.html#surprise-song-color-groups",
    "href": "viz.html#surprise-song-color-groups",
    "title": "2  Visualizing surprise song outfits",
    "section": "Surprise song color groups",
    "text": "Surprise song color groups\n\nsurpriseSongsDressColours$groupName <- sapply(surpriseSongsDressColours$DressName, function(color) {\n  if (color %in% c(\"Pink\", \"Flamingo pink\")) return(\"reds\")\n  if (color %in% c(\"Green\")) return(\"greens\")\n  if(color %in% c(\"Yellow\", \"Sunset orange\")) return(\"yellows\")\n  if (color %in% c(\"Ocean blue\", \"Blue\", \"Blurple\")) return (\"blues\")\n  if (color %in% c(\"Popsicle\", \"Cotton candy\", \"Grapefruit\")) return (\"colorful\")\n  return(\"Neutral\")\n})\n\nsongs_with_single_color_group <- surpriseSongsDressColours %>%\n  group_by(`Song title`) %>%\n  summarize(\n    total_performances = n(),\n    unique_color_groups = n_distinct(groupName),\n    color_group = first(groupName) \n  ) %>%\n  filter(unique_color_groups == 1, total_performances > 1) %>%\n  arrange(desc(total_performances))\n\nsingle_color_performances <- surpriseSongsDressColours %>%\n    filter(`Song title` %in% songs_with_single_color_group$`Song title`)\n\n## pics\nblues <- paste(\"dress_images/images_high_res/cropped/\", c(\"blue\", \"ocean_blue\", \"blurple\"), \".jpg\", sep = \"\")\nreds <- paste(\"dress_images/images_high_res/cropped/\", c(\"pink\", \"flamingo_pink\"), \".jpg\", sep = \"\")\nyellows <- paste(\"dress_images/images_high_res/cropped/\", c(\"yellow\", \"sunset_orange\"), \".jpg\", sep = \"\")\n\ncoords <- circleProgressiveLayout(table(single_color_performances$groupName),\n                                  sizetype = 'area')\ncoords$id <- names(table(single_color_performances$groupName))\ndf.gg <- circleLayoutVertices(coords, npoints = 8, id = 4)\nsnames <- single_color_performances %>% select('Song title', groupName) %>%\n    group_by(`Song title`) %>% mutate(count = n()) %>% ungroup() |> unique()\nset.seed(1984) ## for jitter repel\nplot <- ggplot() + theme_void() +\n    ## blues\n    geom_polygon(data = df.gg[df.gg$id == \"blues\",], aes(x = x, y = y),\n                 fill = \"#0000FF\", alpha = 0.05) +\n    geom_text_repel(aes(x = coords$x[1], \n                        y = coords$y[1], \n                        label = snames$`Song title`[snames$groupName == \"blues\"]),\n                    col = \"#0000FF\", nudge_y = -1.1, nudge_x = 0.1, segment.color = NA,\n                    size = 1.5*snames$count[snames$groupName == \"blues\"], box.padding = 0.1,\n                    family = \"Gill Sans MT\") +\n    ## reds\n    geom_polygon(data = df.gg[df.gg$id == \"reds\",], aes(x = x, y = y),\n                 fill = \"#FF0000\", alpha = 0.05)  +\n    geom_text_repel(aes(x = coords$x[2], \n                        y = coords$y[2], \n                        label = snames$`Song title`[snames$groupName == \"reds\"]),\n                    col = \"#FF0000\", nudge_y = -0.9, nudge_x = 0.1, segment.color = NA,\n                    size = 1.5*snames$count[snames$groupName == \"reds\"], box.padding = 0.1,\n                    family = \"Gill Sans MT\") +\n    ## yellows\n    geom_polygon(data = df.gg[df.gg$id == \"yellows\",], aes(x = x, y = y),\n                 fill = \"#FFD700\", alpha = 0.05)  +\n    geom_text_repel(aes(x = coords$x[3], \n                        y = coords$y[3], \n                        label = snames$`Song title`[snames$groupName == \"yellows\"]),\n                    col = \"#FFD700\", nudge_y = 1.4, nudge_x = 0, segment.color = NA,\n                    size = 1.5*snames$count[snames$groupName == \"yellows\"], box.padding = 0.1,\n                    family = \"Gill Sans MT\")\n\n## image sizes relative to\n## table(single_color_performances$DressName, single_color_performances$groupName)\nset.seed(1984) ## for jitter repel\nggdraw() +\n    draw_plot(plot) +\n    draw_image(blues[1], -0.37, 0.23, scale = 0.5/3) +\n    draw_image(blues[2],  -0.2, 0.32, scale = 0.8/3) +\n    draw_image(blues[3],  -0.07, 0.26, scale = 0.4/3) +\n    draw_image(reds[1], 0.1, 0.27, scale = 0.8/3) +\n    draw_image(reds[2],  0.3, 0.33, scale = 0.7/3) +\n    draw_image(yellows[1], -0.1, -0.25, scale = 0.7/3) +\n    draw_image(yellows[2],  0.1, -0.3, scale = 1.1/3)"
  },
  {
    "objectID": "outfit_transitions.html#a-chi2-test-for-the-transition-counts",
    "href": "outfit_transitions.html#a-chi2-test-for-the-transition-counts",
    "title": "3  Are the surprise song outfits random?",
    "section": "3.1 A \\(\\chi^2\\)-test for the transition counts",
    "text": "3.1 A \\(\\chi^2\\)-test for the transition counts\nLikely, the first standard hypothesis test you think of for count/contingency data is the \\(\\chi^2\\)-test (or the chi-squared test). Essentially, this works by testing for equal transition rates (if the outfit choices were completely random we’d expect equal numbers of transitions between the outfits); Slightly more formally,\n\\(H_0 = \\text{row outfits independent of column outfits}\\) vs. \\(H_1 = \\text{row outfits not independent of column outfits}\\).\n\n## first leg\nfirst_leg |> transitions() |> chisq.test()\n\n\n    Pearson's Chi-squared test\n\ndata:  transitions(first_leg)\nX-squared = 10.259, df = 9, p-value = 0.33\n\n## europe leg\nmid_leg |> transitions() |> chisq.test()\n\n\n    Pearson's Chi-squared test\n\ndata:  transitions(mid_leg)\nX-squared = 19.554, df = 4, p-value = 0.0006115\n\n## final leg\nfinal_leg |> transitions() |> chisq.test()\n\n\n    Pearson's Chi-squared test\n\ndata:  transitions(final_leg)\nX-squared = 17.337, df = 16, p-value = 0.3641\n\n\n\n\n\n\nTable 3.1: Summary of the chi-squared tests on the transition matricies for each leg of the Eras tour.\n\n\n\nChi-squared statistic\nDegrees of freedom\np-vlaue\n\n\n\n\nFirst Leg\n10.259\n9\n0.330\n\n\nEuropean Leg\n19.554\n4\n0.001\n\n\nFinal Leg\n17.337\n16\n0.364\n\n\n\n\n\n\nTherefore, if our \\(\\chi^2\\) assumptions were met we might infer that there’s some evidence against the outfits for the European leg being random.\n\n\n\n\n\nChi-squared distribution under the NULL hypothesis for each leg along with the observed chi-squared statistic in purple."
  },
  {
    "objectID": "outfit_transitions.html#a-randomisation-test",
    "href": "outfit_transitions.html#a-randomisation-test",
    "title": "3  Are the surprise song outfits random?",
    "section": "3.2 A randomisation test",
    "text": "3.2 A randomisation test\nIf we’re not happy that our parametric assumptions are met then we can (often) fall back on simple resampling methods; basically simulating what would happen under chance alone and then comparing how our observed situation stack up!\nTo begin with let’s use the \\(\\chi^2\\)-squared statistic to represent the transition matrix we observed for each leg (it is a valid metric comparing between what we expected under independence and what we observed). By using a randomisation test we can build up a sampling distribution of this chosen metric that represent what would happen under chance alone (i.e., without any assumptions about the shape of this distribution). Our observed statistics in this case are given in the first column of Table 3.1.\n\n## create a function for the randomisation test using chi-sq\n## on the transition matrix, using a for loop just bc\n\nrandomisation <- function(data, nreps = 1000, seed = 1984){\n  sampling_dist <- numeric(nreps)\n  set.seed(seed) \n  for (i in 1:nreps) {\n   sampling_dist[i] <- suppressWarnings(sample(data) |> \n                                          transitions() |> \n                                          chisq.test())$statistic\n  }\nreturn(sampling_dist)\n}\n\nCalculating a p-value (note they’re all pretty much the same as above!).\n\n## first leg\nnull_first <- randomisation(first_leg)\nmean(null_first >= (first_leg |> transitions() |> chisq.test())$statistic)\n\n[1] 0.336\n\n## European leg\nnull_mid <- randomisation(mid_leg)\nmean(null_mid >= (mid_leg |> transitions() |> chisq.test())$statistic)\n\n[1] 0.001\n\n## Final leg\nnull_final <- randomisation(final_leg)\nmean(null_final >= (final_leg |> transitions() |> chisq.test())$statistic)\n\n[1] 0.322\n\n\n\n\n\n\n\nSampling distribution of the test statistic (the chi-squared statistic) under the NULL hypothesis for each leg along with the observed test statistic in purple.\n\n\n\n\nBut, we can actually use any metric we like in a randomisation test! For our example, the \\(\\chi^2\\) is a nice (distance) statistic because it considers all the transitions, but if we were particularly interested in, say, a particular transition (e.g., Yellow \\(\\rightarrow\\) Pink for the first leg) we could look at those instead.\n\\(H_0 = \\text{A particular transition occured at random}\\)\nvs. \n\\(H_1 = \\text{A particular transition occured fewer or more times than expected}\\).\n[Note: than expected means than was expected under chance alone.]\n\n## create a new function for the randomisation test using the \n## numbers of a particular transition (from --> to)\n\nrandomisation <- function(data, from = \"Yellow\", to = \"Pink\", \n                          nreps = 1000, seed = 1984){\n  sampling_dist <- numeric(nreps)\n  set.seed(seed) \n  for (i in 1:nreps) {\n   sampling_dist[i] <- (sample(data) |> transitions())[from, to]\n  }\nreturn(sampling_dist)\n}\n\nCalculating a two-sided p-value.\n\n## first leg, Yellow --> Pink (default)\nnull_first <- randomisation(first_leg)\nobs_first <- (first_leg |> transitions())[\"Yellow\", \"Pink\"]\nmean(abs(null_first - mean(null_first)) >= abs(obs_first - mean(null_first)))\n\n[1] 0.199\n\n## European leg, Sunset orange --> Flamingo pink\nnull_mid <- randomisation(mid_leg, from = \"Sunset orange\", to = \"Flamingo pink\")\nobs_mid <- (mid_leg |> transitions())[\"Sunset orange\", \"Flamingo pink\"]\nmean(abs(null_mid - mean(null_mid)) >= abs(obs_mid - mean(null_mid)))\n\n[1] 0.766\n\n## Final leg, Blurple --> Blurple\nnull_final <- randomisation(final_leg, from = \"Blurple\", to = \"Blurple\")\nobs_final <- (final_leg |> transitions())[\"Blurple\", \"Blurple\"]\nmean(abs(null_final - mean(null_final)) >= abs(obs_final - mean(null_final)))\n\n[1] 0.644\n\n\n\n\n\n\n\nSampling distribution of the test statistic (the number of times a particular transition occured) under the NULL hypothesis for each leg along with the observed test statistic in purple.\n\n\n\n\nIn each case, no evidence to suggest we see the particular transitions more or less frequently than would be expected under the NULL hypothesis of chance alone. (Note the transitions were chosen arbitrarily)"
  },
  {
    "objectID": "outfit_transitions.html#a-likelihood-ratio-test",
    "href": "outfit_transitions.html#a-likelihood-ratio-test",
    "title": "3  Are the surprise song outfits random?",
    "section": "3.3 A likelihood ratio test",
    "text": "3.3 A likelihood ratio test\nWhat about using a model based approach? If the outfits were random (given the choices) then we’d expect each to occur independently of one another (i.e., the chance of one outfit is independent of any other).\nLet’s consider the first leg, defining the events mathematically we let \\(\\{X_1, X_2, \\ldots, X_n\\}\\) be the outfits taking values in \\(\\{\\text{Blue}, \\text{Green}, \\text{Pink}, \\text{Yellow}\\}\\) (i.e., four possible categories).\nIf the outfits were independent then we can write the likelihood as\n\\[L_0(p; x) = \\prod_{t=1}^{n} P(X_t = x_t) = \\prod_{j=1}^{4} p_j^{n_j}\\].\nHere \\(p_j\\) is the probability of observing category \\(j\\), \\(n_j\\) is the number of times category \\(j\\) appears from \\(t=2\\) to \\(n\\), and \\(\\sum_{j=1}^{k} p_j = 1\\). The log-likelihood is therefore \\[\\log L_0(p;x) = \\sum_{t=2}^{n} \\log p_{x_t} = \\sum_{j=1}^{4} n_j \\log p_j\\].\nCalculating this in R step-by-step\n\nn <- length(first_leg)\nn\n\n[1] 81\n\nk <- length(unique(first_leg))\nk\n\n[1] 4\n\nchain <- as.factor(first_leg)\nchain\n\n [1] Pink   Green  Pink   Green  Green  Pink   Yellow Pink   Green  Yellow\n[11] Pink   Green  Green  Pink   Yellow Pink   Green  Yellow Pink   Yellow\n[21] Green  Yellow Green  Pink   Pink   Green  Yellow Pink   Green  Yellow\n[31] Pink   Yellow Yellow Pink   Green  Pink   Pink   Yellow Yellow Pink  \n[41] Green  Pink   Pink   Yellow Pink   Pink   Pink   Pink   Yellow Green \n[51] Blue   Blue   Pink   Green  Yellow Blue   Pink   Yellow Yellow Blue  \n[61] Green  Blue   Yellow Green  Blue   Yellow Pink   Green  Yellow Pink  \n[71] Blue   Pink   Blue   Yellow Green  Yellow Green  Pink   Pink   Yellow\n[81] Blue  \nLevels: Blue Green Pink Yellow\n\np_indep <- table(chain) / n\np_indep ## independent probabilities\n\nchain\n     Blue     Green      Pink    Yellow \n0.1111111 0.2469136 0.3580247 0.2839506 \n\np_indep[as.integer(chain)] ## probabilities of each element as they occur\n\nchain\n     Pink     Green      Pink     Green     Green      Pink    Yellow      Pink \n0.3580247 0.2469136 0.3580247 0.2469136 0.2469136 0.3580247 0.2839506 0.3580247 \n    Green    Yellow      Pink     Green     Green      Pink    Yellow      Pink \n0.2469136 0.2839506 0.3580247 0.2469136 0.2469136 0.3580247 0.2839506 0.3580247 \n    Green    Yellow      Pink    Yellow     Green    Yellow     Green      Pink \n0.2469136 0.2839506 0.3580247 0.2839506 0.2469136 0.2839506 0.2469136 0.3580247 \n     Pink     Green    Yellow      Pink     Green    Yellow      Pink    Yellow \n0.3580247 0.2469136 0.2839506 0.3580247 0.2469136 0.2839506 0.3580247 0.2839506 \n   Yellow      Pink     Green      Pink      Pink    Yellow    Yellow      Pink \n0.2839506 0.3580247 0.2469136 0.3580247 0.3580247 0.2839506 0.2839506 0.3580247 \n    Green      Pink      Pink    Yellow      Pink      Pink      Pink      Pink \n0.2469136 0.3580247 0.3580247 0.2839506 0.3580247 0.3580247 0.3580247 0.3580247 \n   Yellow     Green      Blue      Blue      Pink     Green    Yellow      Blue \n0.2839506 0.2469136 0.1111111 0.1111111 0.3580247 0.2469136 0.2839506 0.1111111 \n     Pink    Yellow    Yellow      Blue     Green      Blue    Yellow     Green \n0.3580247 0.2839506 0.2839506 0.1111111 0.2469136 0.1111111 0.2839506 0.2469136 \n     Blue    Yellow      Pink     Green    Yellow      Pink      Blue      Pink \n0.1111111 0.2839506 0.3580247 0.2469136 0.2839506 0.3580247 0.1111111 0.3580247 \n     Blue    Yellow     Green    Yellow     Green      Pink      Pink    Yellow \n0.1111111 0.2839506 0.2469136 0.2839506 0.2469136 0.3580247 0.3580247 0.2839506 \n     Blue \n0.1111111 \n\np_indep[as.integer(chain)] |> log() ## log probabilities of each element as they occur\n\nchain\n     Pink     Green      Pink     Green     Green      Pink    Yellow      Pink \n-1.027153 -1.398717 -1.027153 -1.398717 -1.398717 -1.027153 -1.258955 -1.027153 \n    Green    Yellow      Pink     Green     Green      Pink    Yellow      Pink \n-1.398717 -1.258955 -1.027153 -1.398717 -1.398717 -1.027153 -1.258955 -1.027153 \n    Green    Yellow      Pink    Yellow     Green    Yellow     Green      Pink \n-1.398717 -1.258955 -1.027153 -1.258955 -1.398717 -1.258955 -1.398717 -1.027153 \n     Pink     Green    Yellow      Pink     Green    Yellow      Pink    Yellow \n-1.027153 -1.398717 -1.258955 -1.027153 -1.398717 -1.258955 -1.027153 -1.258955 \n   Yellow      Pink     Green      Pink      Pink    Yellow    Yellow      Pink \n-1.258955 -1.027153 -1.398717 -1.027153 -1.027153 -1.258955 -1.258955 -1.027153 \n    Green      Pink      Pink    Yellow      Pink      Pink      Pink      Pink \n-1.398717 -1.027153 -1.027153 -1.258955 -1.027153 -1.027153 -1.027153 -1.027153 \n   Yellow     Green      Blue      Blue      Pink     Green    Yellow      Blue \n-1.258955 -1.398717 -2.197225 -2.197225 -1.027153 -1.398717 -1.258955 -2.197225 \n     Pink    Yellow    Yellow      Blue     Green      Blue    Yellow     Green \n-1.027153 -1.258955 -1.258955 -2.197225 -1.398717 -2.197225 -1.258955 -1.398717 \n     Blue    Yellow      Pink     Green    Yellow      Pink      Blue      Pink \n-2.197225 -1.258955 -1.027153 -1.398717 -1.258955 -1.027153 -2.197225 -1.027153 \n     Blue    Yellow     Green    Yellow     Green      Pink      Pink    Yellow \n-2.197225 -1.258955 -1.398717 -1.258955 -1.398717 -1.027153 -1.027153 -1.258955 \n     Blue \n-2.197225 \n\nll0 <- p_indep[as.integer(chain)] |> log() |> sum() ## log likelihood\nll0\n\n[1] -106.4928\n\n\nNow, what about the likelihood if we assume the sequence of outfits is a first-order Markov chain (i.e., the current outfit \\(X_t\\) depends on the previous one \\(X_{t-1}\\)):\n\\[P(X_t = x_t \\mid X_{t-1} = x_{t-1}) = P_{x_{t-1}, x_t}.\\]\nHere \\(P_{i,j}\\) is the probability of transitioning from state \\(i\\) to state \\(j\\), again with \\(\\sum_{j=1}^{k} P_{i,j} = 1 \\quad \\text{for all } i\\). We can write the likelihood as\n\\[L_1(p;x_t|x_{t-1}) = \\prod_{t=2}^{n} P(X_t = x_t \\mid X_{t-1} = x_{t-1}) = \\prod_{i=1}^{k} \\prod_{j=1}^{k} P_{i,j}^{N_{i,j}}\\]\nWhere \\(N_{i,j}\\) is the number of transitions from state \\(i\\) to state \\(j\\). The log-likelihood is then\n\\[\\log(L_1(p;x_t|x_{t-1})) = \\sum_{t=2}^{n} \\log (P_{x_{t-1}, x_t}) = \\sum_{i=1}^{k} \\sum_{j=1}^{k} N_{i,j} \\log (P_{i,j})\\]\nCalculating this in R step-by-step\n\n## transition probability matrix\ntm <- prop.table(transitions(first_leg), 1) ## over rows\ntm\n\n        \n               Blue      Green       Pink     Yellow\n  Blue   0.12500000 0.12500000 0.37500000 0.37500000\n  Green  0.15000000 0.10000000 0.35000000 0.40000000\n  Pink   0.06896552 0.37931034 0.24137931 0.31034483\n  Yellow 0.13043478 0.26086957 0.47826087 0.13043478\n\n## using a for loop\nll1 <- 0 ## initialise\nfor(i in 2:n){\n  lli <- log(tm[chain[i-1], chain[i]]) ## element of tm\n  ll1 <- ll1 + lli\n}\nll1 ## log likelihood assuming a first-order Markov chain\n\n[1] -99.9088\n\n## we can benchmark using the markovchain package \nmarkovchain::markovchainFit(data = first_leg, method = \"mle\")$logLikelihood\n\n[1] -99.9088\n\n\nConstruction a likelihood ratio test statistic\n\\[\\Lambda = 2 \\left( \\log(L_1(p;x_t|x_{t-1}))  - \\log(L_0(p; x)) \\right)\\]\nUnder the NULL hypothesis \\(H_0\\), the test statistic \\(\\Lambda\\) asymptotically follows a \\(\\chi^2\\) distribution with degrees of freedom \\(\\text{df} = (k - 1)^2\\).\nIn R\n\ndelta <- 2 * (ll1 - ll0)\ndf <- (k - 1)^2\np_val <- pchisq(delta, df, lower.tail = FALSE)\n\nNo evidence against the outfits being independent.\n\n\n\n\n\nDistribution of the test statistic under the NULL hypothesis, the observed value shown in purple.\n\n\n\n\nSo, let’s make a function.\n\nlrt <- function(x, plot = FALSE){\n  ## under H0\n  n <- length(x)\n  k <- length(unique(x))\n  chain <- as.factor(x)\n  p_indep <- table(chain) / n\n  ll0 <- p_indep[as.integer(chain)] |> log() |> sum() \n  ## first-order Markov\n  tm <- prop.table(transitions(x), 1) \n  ll1 <- 0 \n  for(i in 2:n){\n    lli <- log(tm[chain[i-1], chain[i]]) \n    ll1 <- ll1 + lli\n  }\n  ## test statistic\n  delta <- 2 * (ll1 - ll0)\n  df <- (k - 1)^2\n  p_val <- pchisq(delta, df, lower.tail = FALSE)\n  if(plot){\n    chi <- data.frame(x = seq(0, 30, length.out = 100))\n    chi$density <- dchisq(chi$x, df = df)\n    chi %>%\n      ggplot(aes(x = x, y = density)) +\n      geom_line(linewidth = 2) +\n      geom_vline(aes(xintercept = delta), linetype = \"dashed\", color = \"purple\") +\n      labs(title = \"\",x = \"\", y = \"\") + theme_bw() -> p\n    print(p)\n  }\n  ## info to return\n  return(list(\"ll0\" = ll0,\n              \"ll1\" = ll1,\n              \"delta\" = delta,\n              \"df\" = df,\n              \"p.val\" = p_val))\n}\n\nlrt(first_leg)\n\n$ll0\n[1] -106.4928\n\n$ll1\n[1] -99.9088\n\n$delta\n[1] 13.16793\n\n$df\n[1] 9\n\n$p.val\n[1] 0.1551535\n\nlrt(mid_leg, plot = TRUE)\n\n\n\n\n$ll0\n[1] -52.30575\n\n$ll1\n[1] -39.26825\n\n$delta\n[1] 26.075\n\n$df\n[1] 4\n\n$p.val\n[1] 3.056156e-05\n\nlrt(final_leg, plot = TRUE)\n\n\n\n\n$ll0\n[1] -26.26847\n\n$ll1\n[1] -14.04639\n\n$delta\n[1] 24.44415\n\n$df\n[1] 16\n\n$p.val\n[1] 0.08024261\n\n\nFirst order Markov chain?\nSo, might we believe that for the European leg of her tour Swift’s outfits weren’t random and perhaps what she wore one night depended on her outfit the previous night (i.e., in stats speak followed a first-order Markov chain)?\n\n\n\n\n\n\nNote\n\n\n\nBasically, the first-order Markov property is that the future state of a system depends only on its current state and is independent of its past history.\n\n\n\nrequire(markovchain)\nverifyMarkovProperty(mid_leg) ## no evidence against the Markov property p-value 0.834 (~likely a Markov chain?)\n\nTesting markovianity property on given data sequence\nChi - square statistic is: 7.339583 \nDegrees of freedom are: 12 \nAnd corresponding p-value is: 0.8343811 \n\nmarkovchainFit(data = mid_leg, method = \"mle\") ## as above but with ses :)\n\n$estimate\nMLE Fit \n A  3 - dimensional discrete Markov Chain defined by the following states: \n Flamingo pink, Ocean blue, Sunset orange \n The transition matrix  (by rows)  is defined as follows: \n              Flamingo pink Ocean blue Sunset orange\nFlamingo pink    0.06666667  0.2666667     0.6666667\nOcean blue       0.57142857  0.0000000     0.4285714\nSunset orange    0.27777778  0.5555556     0.1666667\n\n\n$standardError\n              Flamingo pink Ocean blue Sunset orange\nFlamingo pink    0.06666667  0.1333333    0.21081851\nOcean blue       0.20203051  0.0000000    0.17496355\nSunset orange    0.12422600  0.1756821    0.09622504\n\n$confidenceLevel\n[1] 0.95\n\n$lowerEndpointMatrix\n              Flamingo pink  Ocean blue Sunset orange\nFlamingo pink    0.00000000 0.005338081    0.25346989\nOcean blue       0.17545597 0.000000000    0.08564909\nSunset orange    0.03429924 0.211224910    0.00000000\n\n$upperEndpointMatrix\n              Flamingo pink Ocean blue Sunset orange\nFlamingo pink     0.1973310  0.5279953     1.0000000\nOcean blue        0.9674012  0.0000000     0.7714938\nSunset orange     0.5212563  0.8998862     0.3552643\n\n$logLikelihood\n[1] -39.26825\n\n\nWhat about 1st vs 2nd Markov Chain\n\n## Let's trick markovchain into doing this for us\n## by creating a \"first order\" chain which is actually of order 2\n\nsnap <- data.frame(current = mid_leg)\nsnap$future <- lead(snap$current, 1)\nsnap$past <- lag(snap$current, 1)\n\nsec_order <- snap |>\n  filter(!is.na(future) & !is.na(past)) %>%\n  tidyr::unite(\"y_current\", c(\"past\", \"current\"), remove = FALSE) |>\n  mutate(y_next = lead(y_current, 1),\n         y_previous = lag(y_current, 1))\n\nll1 <- markovchainFit(data = mid_leg, method = \"mle\")$logLikelihood\nll1\n\n[1] -39.26825\n\nll2 <- markovchainFit(data = sec_order$y_current, method = \"mle\")$logLikelihood\nll2 ## eyeballing this, looks pretty similar to 1st order\n\n[1] -32.29189\n\n\nFor fun let’s also calculate the 2nd order Markov Chain likelihood manually.\n\n## function to calculate the log likelihood assuming a second-order Markov chain\nll2 <- function(x){\n  n <- length(x)\n  k <- length(unique(x))\n  chain <- as.factor(x)\n  ## Initialize 3D transition count array\n  counts <- array(0, dim = c(k, k, k))\n  int <- as.integer(chain)\n  for (t in 3:n) {\n    a <- int[t - 2]\n    b <- int[t - 1]\n    c <- int[t]\n    counts[a, b, c] <- counts[a, b, c] + 1\n    }\n  ## Calculate conditional probabilities\n  probs <- counts\n  for (a in 1:k) {\n    for (b in 1:k) {\n      total <- sum(counts[a, b, ])\n    if (total > 0) {probs[a, b, ] <- counts[a, b, ] / total}\n      }\n    }\n  ll <- 0\n  for (t in 3:n) {\n    a <- int[t - 2]\n    b <- int[t - 1]\n    c <- int[t]\n    p <- probs[a, b, c]\n    if (p > 0) {ll <- ll + log(p)}\n  }\n  return(ll)\n}\n## 2nd order Markov Chain log-likelihood\nll2(mid_leg)\n\n[1] -32.88436"
  },
  {
    "objectID": "colour_sentiments.html#chi2-test-for-equal-proportions",
    "href": "colour_sentiments.html#chi2-test-for-equal-proportions",
    "title": "4  Colour Sentiments",
    "section": "4.1 \\(\\chi^2\\) test for equal proportions",
    "text": "4.1 \\(\\chi^2\\) test for equal proportions\n\ncolorSentimentScores$colourGroup <- colorGroups[colorSentimentScores$colour]\ncols.df <- as.data.frame.matrix(table(colorSentimentScores$colourGroup, colorSentimentScores$meaning))\ncols.df\n\n                negative neutral positive\nblack and white        2       2        0\nblacks                 3       7        3\nblues                 18       7       10\ncolorful               1       3       11\ngreens                 0       3        8\npurples                1       1        4\nreds                  15      11       13\nwhites                13      12        5\nyellows                1       9       17\n\n## change col and row names for aesthetic reasons\ncolnames(cols.df) <- str_to_title(colnames(cols.df))\nrownames(cols.df) <- str_to_title(rownames(cols.df))\nrow.props <- prop.table(as.matrix(cols.df), margin = 1)\ncorrplot(row.props, is.corr = FALSE, cl.pos = FALSE)\n\n\n\n\nThe plot above is not a traditional correlation plot, rather each entry is the row-wise proportion of colour mentions across each sentiment. The shade and size of each circle represent the magnitude of each entry, where darker and larger circles correspond to larger row-wise proportions. Evident from this plot is that for Yellows, Purples, Greens and Colorful we see a higher proportion of mentions associated with Positive sentiment.\nBelow we carry out a (Pearson’s) chi-squared test where the null hypothesis is that the joint distribution of the cell counts is the product of the row and column marginals:\n\\(H0\\): colours and sentiments are independent vs \\(H1\\): colours and sentiments are dependent,\n\n## chi-squared test\nchi <- chisq.test(cols.df)\nchi ## strong evidence against NULL\n\n\n    Pearson's Chi-squared test\n\ndata:  cols.df\nX-squared = 47.661, df = 16, p-value = 5.369e-05\n\ncorrplot(chi$residuals, is.corr = FALSE, cl.pos = FALSE)\n\n\n\n\nAgain, the plot above is not a traditional correlation plot, each entry is the \\(\\chi^2\\) residual (i.e., a measure of deviation from the expected). Red hues indicate fewer than expected counts, and blue hues indicate higher counts than were expected. The sizes and shade of each circle reflect the magnitude of the deviation. Looking at the Yellow row we see that we observe far fewer mentions with negative sentiment and more mentions with positive sentiment, than we might expect under equal counts. Referring back to the table of counts this is clear to see."
  },
  {
    "objectID": "colour_sentiments.html#correspondence-analysis",
    "href": "colour_sentiments.html#correspondence-analysis",
    "title": "4  Colour Sentiments",
    "section": "4.2 Correspondence analysis",
    "text": "4.2 Correspondence analysis\nSo, as we suspected from the table alone it seems likely that there is some dependence between colour mentions (in Taylor’s lyrics) and the sentiment of the lyrics. What we’d like to do is further delve into the association between colours and their associated sentiment in Taylor’s lyrics. To do this we can carry out correspondence analysis (CA):\n\ncoa <- FactoMineR::CA(cols.df)\n\n\n\n\nThe biplot above shows the relative positions of the rows (colours) and the columns (sentiments). This is not a typical scatter plot and distances* between points cannot neccesarily be interpreted as you would do if it were. Now, we are not interested in representing the contingency table above in a lower dimension space using correspondence analysis. Rather, we are interested in the relative associations between colours and sentiment. The plot above is termed a symmetric plot and shows a global pattern: the distance between any row points (colours) or column points (sentiments) gives a measure of their similarity or dissimilarity, we cannot from this plot compare associations between colours and sentiments directly. However, in general we can see that Yellows, Purples, Greens and Colorful are mainly mentioned in association with Positive sentiments etc.\nIn order to interpret the distance between sentiments and colours we need to use an asymmetric biplot (see below).\nFirst, let’s describe each dimension. (Note this should be done with care! Avoid reification (i.e., reading something tangible into the dimensions)). We are particularly interested in the sentiments (i.e., column variables) representation of the dimenesions.\n\ncoa$col$coord\n\n               Dim 1      Dim 2\nNegative  0.60492700 -0.1746621\nNeutral   0.07774606  0.3226498\nPositive -0.52031114 -0.1170984\n\n## plotting\ndata.frame(coa$col$coord) %>%\n  mutate(variables = rownames(.)) %>%\n  pivot_longer(., cols = 1:2) %>%\n  ggplot(aes(value, variables, fill = value)) +\n  geom_col() +\n  geom_vline(xintercept = 0, lty = \"dashed\", col = \"darkgrey\", linewidth = 2) +\n  facet_wrap(~name, scales = \"free_y\") +\n    labs(fill = \"Relative\\ncontribution\",y = NULL, x = NULL) +\n  theme_bw() + scale_fill_gradient2(low = \"darkblue\", mid = \"white\",high = \"darkred\")\n\n\n\n\nEach panel of the plot above shows the relative contribution of sentiments to each new dimension. The size and shade of each bar represents the magnitude of the contribution. The vertical grey line (at 0) highlights the direction of the contributions.\nTherefore (roughly speaking) lower -ve values in Dim 1 are more Positive in sentiment and +ve values are more Negative (values close to 0 are Neutral). The absolute direction of the values here are meaningless; it is the relative direction we are interested in, and so Dim 1 can be thought of as a measure of either Positive or Negative sentiment (let’s call it feeling). Dim 2 might be thought of as conviction of sentiment (or feeling), higher values reflecting Neutral feelings.\nNow, let’s look the degree of association between the rows (colours) and the axes. The returned cos2 measure represents the quality of representation (i.e., degree of association), it takes values between 0 and 1.\n\ncoa$row$cos2\n\n                     Dim 1        Dim 2\nBlack And White 0.81876976 0.1812302419\nBlacks          0.06600422 0.9339957761\nBlues           0.66084920 0.3391507987\nColorful        0.95390800 0.0460919952\nGreens          0.99970382 0.0002961754\nPurples         0.80178643 0.1982135704\nReds            0.85809051 0.1419094921\nWhites          0.88762796 0.1123720391\nYellows         0.95677338 0.0432266171\n\ncorrplot(coa$row$cos2, is.corr = FALSE, cl.pos = FALSE)\n\n\n\n\nAgain, this is not a traditional correlation plot. Each entry represents the association between the colours (row vaiables) and the dimensions. From this all colours (bar Blacks) are strongly associated with the feelings dimension. Mentions of the Blacks colour groupings are more associated with Dim 2 the conviction dimension; this, is also evident from the contingency table above where most mentions of this group were associated with Neutral sentiments.\nIdeally, what we’d like to do is both compare the association between colour groups AND the associations between colour groups and sentiments. To do this we create an asymmetric biplot and represent columns (sentiment) in row (colours) in space (by setting map = \"rowprincipal\" in the call to fviz_ca_biplot() below). Doing this also better shows the relationships between the colours.\nrowprincipal normalization: the distances between the row labels are meaningful and consistent with those shown in the principal normalization, but the differences between the column coordinates are now misleading. columnprincipal: the distances between the row points are not correct\n\n## row/colour contribution asymmetric biplot \nfviz_ca_biplot(coa, repel = TRUE, col.col = \"brown\", col.row = \"purple\",\n               map = \"rowprincipal\", arrows = c(TRUE,TRUE)) + ggtitle(\"\") +\n  theme_void()\n\n\n\n\nAdding arrows to the biplot let’s us assess the degree of association between colours and sentiments. Again, this is not a typical scatter plot! An acute angle between two arrows indicates a strong association between the corresponding row (colour) and column (sentiment). From the plot above Purples have the strongest association with Positive sentiment, Reds & Blues with Negative and Blacks with Neutral. In summary, acute angles between colours and sentiment suggest positive association, right angles suggest independence, and obtuse angles suggest negative association.\n\n4.2.1 Reducing dimensions\nIt’s not like we have swaths of variables! But, let’s explore! We saw from above that each colour (bar Blacks) was strongly associated with the first dimension (i.e., feelings). Below we look as the percentage of variation explained by each dimension.\n\ncoa$eig\n\n      eigenvalue percentage of variance cumulative percentage of variance\ndim 1 0.21841337                82.4876                           82.4876\ndim 2 0.04636992                17.5124                          100.0000\n\n\nDim 1 (i.e., feelings) explains ~82% of the total variation. Pretty much most of it! This makes sense as it is basically a rotation of the linear sentiment scale we initially assumed when scoring the lyrics! Let’s have a look as this one dimension on it’s own, recall that we’d like to do this and examining the association between colours (i.e., a sapce that represent columns (sentiment) in row (colours) in space).\n\n## grabbing coordinates from plot\np <- fviz_ca_biplot(coa, map = \"rowprincipal\")\ntmp <- ggplot_build(p)\nro <- tmp$data[[2]][,c(1,2,3)]  \nro$colour <- colorPaletteGroups[tolower(ro$label)]\nsents <- tmp$data[[6]][, c(1, 2, 3)]\n\n## atan2 counterclockwise\nangles <- function(rows, cols, row_names, col_names){\n  res <- matrix(0, nrow = nrow(rows), ncol = nrow(cols))\n  for(i in 1:nrow(cols)){\n    angle = atan2(cols[i, 2], cols[i, 1]) - atan2(rows[,2], rows[,1]) \n    ## make between -pi (-180) and pi (180)\n    angle = ifelse(angle > pi, angle - (2*pi), ifelse(angle <= -pi, angle + (2*pi), angle)) *(180/pi)\n    res[, i] = angle\n  }\n  rownames(res) <- row_names\n  colnames(res) <- col_names\n  return(res)\n}\n## 'distances' between rows and cols in row space\nrc <- angles(ro[, 1:2], cols = sents[,1:2], row_names = ro$label, col_names = sents$label)\n## plotting relative to neutral\nrcls <- data.frame(x = rc[,2], col = ro$colour, lab = ro$label)\n## 'distances' between cols in row space\ncc <- angles(sents[, 1:2], cols = sents[,1:2], row_names = sents$label, col_names = sents$label)\nccls <- data.frame(x = cc[,2], lab = sents$label)\n## plot on the \"angle\" line\nggplot(rcls, aes(x = x, y = 1, col = col, label = lab)) +\n  geom_point() + \n  ggrepel::geom_text_repel(aes(col = col), box.padding = 1.5, \n                            arrow = arrow(length = unit(0.1, \"inches\")), alpha = 0.7, size = 4) +\n  scale_color_identity() +\n  geom_hline(yintercept = 1, alpha = 0.3, col = \"grey\") +\n  geom_text(data = ccls, size = 6, col = \"darkgrey\") + theme_void() +\n  theme(panel.background = element_rect(fill = \"#D9D7B6\"))\n\n\n\n\nThe plot above is a 1D representation of the angles between colours and sentiments following the rowprinciple. Clearly Blues and Reds are strongly associated with Negative and Blacks are mostly Neutral etc. NOte that this plot is relative to Neutral sentiment."
  },
  {
    "objectID": "colour_sentiments.html#cluster-analysis-of-ca-colour-scores",
    "href": "colour_sentiments.html#cluster-analysis-of-ca-colour-scores",
    "title": "4  Colour Sentiments",
    "section": "4.3 Cluster analysis of CA colour scores",
    "text": "4.3 Cluster analysis of CA colour scores\nRecall, we are interetsted in the association between colours. Having carried out CA, we have a decent idea of which colours are associated with what semtiments etc. The representation of our colours in reduced dimensinal space are:\n\ncoa$row$coord\n\n                     Dim 1       Dim 2\nBlack And White  0.7303704  0.34361934\nBlacks           0.1313584  0.49413385\nBlues            0.3808608 -0.27284216\nColorful        -0.6968777 -0.15318495\nGreens          -0.7643240  0.01315577\nPurples         -0.4987625 -0.24798828\nReds             0.1736515 -0.07061839\nWhites           0.4418876  0.15722641\nYellows         -0.5975927  0.12702125\n\ncorrplot(coa$row$coord, is.corr = FALSE, cl.pos = FALSE)\n\n\n\n\nRecall from above, we loosely termed Dim1 a measure of feeling (higher values were more Negative) and Dim2 (higher values were more Neutral) a measure of conviction. From the plot above (not a traditional correlation plot) we could infer that Greens were typically associated with strong Positive feelings and Blues with weak Negative feelings and weak convictions (i.e., not-neutral).\n\ndata <- coa$row$coord\n\n## k-means clustering\nset.seed(4321)\n## two clusters\nk2 <- kmeans(data, centers = 2, nstart = 25)\n## three clusters\nk3 <- kmeans(data, centers = 3, nstart = 25)\n## four clusters\nk4 <- kmeans(data, centers = 4, nstart = 25)\n## five clusters\nk5 <- kmeans(data, centers = 5, nstart = 25)\n## six clusters\nk6 <- kmeans(data, centers = 6, nstart = 25)\n\nRather than delve straight into deciding “how many” clusters are appropriate let’s first look at how the colour groupings/clusters change based on our choice of cluster numbers. An alluvial plot shows these transitions nicely, although a bit of set-up is required first! Recall that these clusters are based on the CA coordinates of the colours in what we termed1 feeling and conviction space.\n\nclusters <- data.frame(k2$cluster, k3$cluster, k4$cluster, k5$cluster, k6$cluster)\nclusters <- clusters[c(2, 1, 8, 3, 7, 4, 6, 9, 5),]\nnames(clusters) <- paste(2:6, \"clusters\")\nclusters$Group <- rownames(clusters)\n#clusters$cols <- colorPaletteGroups[tolower(clusters$Group)]\nnames(colorPaletteGroups) <- str_to_title(names(colorPaletteGroups))\n\n# Plot as alluvial\nggplot(clusters,\n       aes(axis1 = `2 clusters`, axis2 = `3 clusters`, axis3 = `4 clusters`,\n           axis4 = `5 clusters`, axis5 = `6 clusters`, y = 1)) +\n  geom_alluvium(aes(fill = Group), width = 1/12, alpha = 0.9, col = \"lightgrey\") +\n  scale_fill_manual(values = colorPaletteGroups, name = \"\") + \n  geom_stratum(width = 1/12, fill = \"pink\", color = \"orchid4\", linewidth = 1.2) +\n  #geom_text(stat = \"stratum\", aes(label = after_stat(stratum))) +\n  theme_void() + theme(legend.position = \"top\")\n\n\n\n\nEach stratum (pink box) represents the number of clusters set from two (far left) to six (far right). These clusters were estimated based on the distances in CA score space where the variables were abstract constructs, which we termed feeling and conviction. That aside, we can see from this alluvial plot which colour groupings are close toegther in this space, and when the split in each cluster occurs. Following Yellows, Purples, Greens and Colorful (which from the start we saw were all closely related with Positive sentiments), when we force the algorithm to choose five clusters, Yellows & Greens separate from Purples & Colorful, whcih by looking at the asymmetric biplot makes sense, despite the clear close association between the four colour groups in the sentiment space, the further subsetting splits according to the maximum distance in this space.\nIf we really want ro choose an appropriate number of clusters then we can use the total within cluster sums of squares (SS), which we’d like to minimize!\n\n## \"best\" representation using a rather 'adhoc'\n## total within SS\nbarplot(c(k2$tot.withinss,k3$tot.withinss,k4$tot.withinss,\n          k5$tot.withinss, k6$tot.withinss),\n        names = paste(2:6,\" clusters\"))\n\n\n\n\nThis is a rather ‘ad hoc’ method, but from the barplot we cannot see much relative tangible reduction in SS after four clusters. So, let’s look at these below.\n\nfviz_cluster(k4, data = data) + theme_bw()\n\n\n\n\nMakes sense based on even our initial CA biplot!"
  }
]