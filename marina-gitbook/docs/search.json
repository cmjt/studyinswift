[
  {
    "objectID": "colour_sentiments.html#chi2-test-for-equal-proportions",
    "href": "colour_sentiments.html#chi2-test-for-equal-proportions",
    "title": "4  Colour Sentiments",
    "section": "4.1 \\(\\chi^2\\) test for equal proportions",
    "text": "4.1 \\(\\chi^2\\) test for equal proportions\n\ncolorSentimentScores$colourGroup &lt;- colourGroups[colorSentimentScores$colour]\ncols.df &lt;- as.data.frame.matrix(table(colorSentimentScores$colourGroup, colorSentimentScores$meaning))\ncols.df\n\n                negative neutral positive\nblack and white        2       2        0\nblacks                 3       7        3\nblues                 18       7       10\ncolourful              1       3       11\ngreens                 0       3        8\npurples                1       1        4\nreds                  15      11       13\nwhites                13      12        5\nyellows                1       9       17\n\n## change col and row names for aesthetic reasons\ncolnames(cols.df) &lt;- str_to_title(colnames(cols.df))\nrownames(cols.df) &lt;- str_to_title(rownames(cols.df))\nrow.props &lt;- prop.table(as.matrix(cols.df), margin = 1)\ncorrplot(row.props, is.corr = FALSE, cl.pos = FALSE)\n\n\n\n\nThe plot above is not a traditional correlation plot, rather each entry is the row-wise proportion of colour mentions across each sentiment. The shade and size of each circle represent the magnitude of each entry, where darker and larger circles correspond to larger row-wise proportions. Evident from this plot is that for Yellows, Purples, Greens and Colorful we see a higher proportion of mentions associated with Positive sentiment.\nBelow we carry out a (Pearson’s) chi-squared test where the null hypothesis is that the joint distribution of the cell counts is the product of the row and column marginals:\n\\(H0\\): colours and sentiments are independent vs \\(H1\\): colours and sentiments are dependent,\n\n## chi-squared test\nchi &lt;- chisq.test(cols.df)\nchi ## strong evidence against NULL\n\n\n    Pearson's Chi-squared test\n\ndata:  cols.df\nX-squared = 47.661, df = 16, p-value = 5.369e-05\n\ncorrplot(chi$residuals, is.corr = FALSE, cl.pos = FALSE)\n\n\n\n\nAgain, the plot above is not a traditional correlation plot, each entry is the \\(\\chi^2\\) residual (i.e., a measure of deviation from the expected). Red hues indicate fewer than expected counts, and blue hues indicate higher counts than were expected. The sizes and shade of each circle reflect the magnitude of the deviation. Looking at the Yellow row we see that we observe far fewer mentions with negative sentiment and more mentions with positive sentiment, than we might expect under equal counts. Referring back to the table of counts this is clear to see."
  },
  {
    "objectID": "colour_sentiments.html#correspondence-analysis",
    "href": "colour_sentiments.html#correspondence-analysis",
    "title": "4  Colour Sentiments",
    "section": "4.2 Correspondence analysis",
    "text": "4.2 Correspondence analysis\nSo, as we suspected from the table alone it seems likely that there is some dependence between colour mentions (in Taylor’s lyrics) and the sentiment of the lyrics. What we’d like to do is further delve into the association between colours and their associated sentiment in Taylor’s lyrics. To do this we can carry out correspondence analysis (CA):\n\ncoa &lt;- FactoMineR::CA(cols.df)\n\n\n\n\nThe biplot above shows the relative positions of the rows (colours) and the columns (sentiments). This is not a typical scatter plot and distances* between points cannot neccesarily be interpreted as you would do if it were. Now, we are not interested in representing the contingency table above in a lower dimension space using correspondence analysis. Rather, we are interested in the relative associations between colours and sentiment. The plot above is termed a symmetric plot and shows a global pattern: the distance between any row points (colours) or column points (sentiments) gives a measure of their similarity or dissimilarity, we cannot from this plot compare associations between colours and sentiments directly. However, in general we can see that Yellows, Purples, Greens and Colorful are mainly mentioned in association with Positive sentiments etc.\nIn order to interpret the distance between sentiments and colours we need to use an asymmetric biplot (see below).\nFirst, let’s describe each dimension. (Note this should be done with care! Avoid reification (i.e., reading something tangible into the dimensions)). We are particularly interested in the sentiments (i.e., column variables) representation of the dimenesions.\n\ncoa$col$coord\n\n               Dim 1      Dim 2\nNegative  0.60492700 -0.1746621\nNeutral   0.07774606  0.3226498\nPositive -0.52031114 -0.1170984\n\n## plotting\ndata.frame(coa$col$coord) %&gt;%\n  mutate(variables = rownames(.)) %&gt;%\n  pivot_longer(., cols = 1:2) %&gt;%\n  ggplot(aes(value, variables, fill = value)) +\n  geom_col() +\n  geom_vline(xintercept = 0, lty = \"dashed\", col = \"darkgrey\", linewidth = 2) +\n  facet_wrap(~name, scales = \"free_y\") +\n    labs(fill = \"Relative\\ncontribution\",y = NULL, x = NULL) +\n  theme_bw() + scale_fill_gradient2(low = \"darkblue\", mid = \"white\",high = \"darkred\")\n\n\n\n\nEach panel of the plot above shows the relative contribution of sentiments to each new dimension. The size and shade of each bar represents the magnitude of the contribution. The vertical grey line (at 0) highlights the direction of the contributions.\nTherefore (roughly speaking) lower -ve values in Dim 1 are more Positive in sentiment and +ve values are more Negative (values close to 0 are Neutral). The absolute direction of the values here are meaningless; it is the relative direction we are interested in, and so Dim 1 can be thought of as a measure of either Positive or Negative sentiment (let’s call it feeling). Dim 2 might be thought of as conviction of sentiment (or feeling), higher values reflecting Neutral feelings.\nNow, let’s look the degree of association between the rows (colours) and the axes. The returned cos2 measure represents the quality of representation (i.e., degree of association), it takes values between 0 and 1.\n\ncoa$row$cos2\n\n                     Dim 1        Dim 2\nBlack And White 0.81876976 0.1812302419\nBlacks          0.06600422 0.9339957761\nBlues           0.66084920 0.3391507987\nColourful       0.95390800 0.0460919952\nGreens          0.99970382 0.0002961754\nPurples         0.80178643 0.1982135704\nReds            0.85809051 0.1419094921\nWhites          0.88762796 0.1123720391\nYellows         0.95677338 0.0432266171\n\ncorrplot(coa$row$cos2, is.corr = FALSE, cl.pos = FALSE)\n\n\n\n\nAgain, this is not a traditional correlation plot. Each entry represents the association between the colours (row vaiables) and the dimensions. From this all colours (bar Blacks) are strongly associated with the feelings dimension. Mentions of the Blacks colour groupings are more associated with Dim 2 the conviction dimension; this, is also evident from the contingency table above where most mentions of this group were associated with Neutral sentiments.\nIdeally, what we’d like to do is both compare the association between colour groups AND the associations between colour groups and sentiments. To do this we create an asymmetric biplot and represent columns (sentiment) in row (colours) in space (by setting map = \"rowprincipal\" in the call to fviz_ca_biplot() below). Doing this also better shows the relationships between the colours.\nrowprincipal normalization: the distances between the row labels are meaningful and consistent with those shown in the principal normalization, but the differences between the column coordinates are now misleading. columnprincipal: the distances between the row points are not correct\n\n## row/colour contribution asymmetric biplot \nfviz_ca_biplot(coa, repel = TRUE, col.col = \"brown\", col.row = \"purple\",\n               map = \"rowprincipal\", arrows = c(TRUE,TRUE)) + ggtitle(\"\") +\n  theme_void()\n\n\n\n\nAdding arrows to the biplot let’s us assess the degree of association between colours and sentiments. Again, this is not a typical scatter plot! An acute angle between two arrows indicates a strong association between the corresponding row (colour) and column (sentiment). From the plot above Purples have the strongest association with Positive sentiment, Reds & Blues with Negative and Blacks with Neutral. In summary, acute angles between colours and sentiment suggest positive association, right angles suggest independence, and obtuse angles suggest negative association.\n\n4.2.1 Reducing dimensions\nIt’s not like we have swaths of variables! But, let’s explore! We saw from above that each colour (bar Blacks) was strongly associated with the first dimension (i.e., feelings). Below we look as the percentage of variation explained by each dimension.\n\ncoa$eig\n\n      eigenvalue percentage of variance cumulative percentage of variance\ndim 1 0.21841337                82.4876                           82.4876\ndim 2 0.04636992                17.5124                          100.0000\n\n\nDim 1 (i.e., feelings) explains ~82% of the total variation. Pretty much most of it! This makes sense as it is basically a rotation of the linear sentiment scale we initially assumed when scoring the lyrics! Let’s have a look as this one dimension on it’s own, recall that we’d like to do this and examining the association between colours (i.e., a sapce that represent columns (sentiment) in row (colours) in space).\n\n## grabbing coordinates from `rowprincipal` plot\nsource(\"code/colourPalettes.r\")\n\np &lt;- fviz_ca_biplot(coa, map = \"rowprincipal\")\ntmp &lt;- ggplot_build(p)\nro &lt;- tmp$data[[2]][,c(1,2,3)]  \nro$colour &lt;- colorPaletteGroups[tolower(ro$label)]\nsents &lt;- tmp$data[[6]][, c(1, 2, 3)]\n\n## atan2 counterclockwise\nangles &lt;- function(rows, cols, row_names, col_names){\n  res &lt;- matrix(0, nrow = nrow(rows), ncol = nrow(cols))\n  for(i in 1:nrow(cols)){\n    angle = atan2(cols[i, 2], cols[i, 1]) - atan2(rows[,2], rows[,1]) \n    ## make between -pi (-180) and pi (180)\n    angle = ifelse(angle &gt; pi, angle - (2*pi), ifelse(angle &lt;= -pi, angle + (2*pi), angle)) *(180/pi)\n    res[, i] = angle\n  }\n  rownames(res) &lt;- row_names\n  colnames(res) &lt;- col_names\n  return(res)\n}\n## 'distances' between rows and cols in row space\nrc &lt;- angles(ro[, 1:2], cols = sents[,1:2], row_names = ro$label, col_names = sents$label)\n## plotting relative to neutral\nrcls &lt;- data.frame(x = rc[,2], col = ro$colour, lab = ro$label)\n## 'distances' between cols in row space (i.e., standard)\ncc &lt;- angles(sents[,1:2], cols = sents[,1:2], row_names = sents$label, col_names = sents$label)\nccls &lt;- data.frame(x = cc[,2], lab = sents$label)\n## plot on the \"angle\" line\nggplot(rcls, aes(x = x, y = 1, col = col, label = lab)) +\n  geom_point() + \n  ggrepel::geom_text_repel(aes(col = col), box.padding = 1.5, \n                            arrow = arrow(length = unit(0.1, \"inches\")), alpha = 0.7, size = 4) +\n  scale_color_identity() +\n  geom_hline(yintercept = 1, alpha = 0.3, col = \"grey\") +\n  geom_text(data = ccls, size = 6, col = \"darkgrey\") + theme_void() +\n  geom_text(data = data.frame(x = c(-180, 180), y = 1), label = c(expression(\"-pi\"), expression(\"pi\")), col = \"grey\", parse = TRUE) +\n  theme(panel.background = element_rect(fill = \"oldlace\"))\n\n\n\n\nThe plot above is a 1D representation of the angles between colours and sentiments following the rowprinciple. Clearly Blues and Reds are strongly associated with Negative and Blacks are mostly Neutral etc. Note that this plot is relative to Neutral sentiment."
  },
  {
    "objectID": "colour_sentiments.html#cluster-analysis-of-ca-colour-scores",
    "href": "colour_sentiments.html#cluster-analysis-of-ca-colour-scores",
    "title": "4  Colour Sentiments",
    "section": "4.3 Cluster analysis of CA colour scores",
    "text": "4.3 Cluster analysis of CA colour scores\nRecall, we are interetsted in the association between colours. Having carried out CA, we have a decent idea of which colours are associated with what semtiments etc. The representation of our colours in reduced dimensinal space are:\n\ncoa$row$coord\n\n                     Dim 1       Dim 2\nBlack And White  0.7303704  0.34361934\nBlacks           0.1313584  0.49413385\nBlues            0.3808608 -0.27284216\nColourful       -0.6968777 -0.15318495\nGreens          -0.7643240  0.01315577\nPurples         -0.4987625 -0.24798828\nReds             0.1736515 -0.07061839\nWhites           0.4418876  0.15722641\nYellows         -0.5975927  0.12702125\n\ncorrplot(coa$row$coord, is.corr = FALSE, cl.pos = FALSE)\n\n\n\n\nRecall from above, we loosely termed Dim1 a measure of feeling (higher values were more Negative) and Dim2 (higher values were more Neutral) a measure of conviction. From the plot above (not a traditional correlation plot) we could infer that Greens were typically associated with strong Positive feelings and Blues with weak Negative feelings and weak convictions (i.e., not-neutral).\n\ndata &lt;- coa$row$coord\n\n## k-means clustering\nset.seed(4321)\n## two clusters\nk2 &lt;- kmeans(data, centers = 2, nstart = 25)\n## three clusters\nk3 &lt;- kmeans(data, centers = 3, nstart = 25)\n## four clusters\nk4 &lt;- kmeans(data, centers = 4, nstart = 25)\n## five clusters\nk5 &lt;- kmeans(data, centers = 5, nstart = 25)\n## six clusters\nk6 &lt;- kmeans(data, centers = 6, nstart = 25)\n\nRather than delve straight into deciding “how many” clusters are appropriate let’s first look at how the colour groupings/clusters change based on our choice of cluster numbers. An alluvial plot shows these transitions nicely, although a bit of set-up is required first! Recall that these clusters are based on the CA coordinates of the colours in what we termed1 feeling and conviction space.\n\nclusters &lt;- data.frame(k2$cluster, k3$cluster, k4$cluster, k5$cluster, k6$cluster)\nclusters &lt;- clusters[c(2, 1, 8, 3, 7, 4, 6, 9, 5),]\nnames(clusters) &lt;- paste(2:6, \"clusters\")\nclusters$Group &lt;- rownames(clusters)\n#clusters$cols &lt;- colourPaletteGroups[tolower(clusters$Group)]\nnames(colourPaletteGroups) &lt;- str_to_title(names(colourPaletteGroups))\n\n# Plot as alluvial\nggplot(clusters,\n       aes(axis1 = `2 clusters`, axis2 = `3 clusters`, axis3 = `4 clusters`,\n           axis4 = `5 clusters`, axis5 = `6 clusters`, y = 1)) +\n  geom_alluvium(aes(fill = Group), width = 1/12, alpha = 0.9, col = \"lightgrey\") +\n  scale_fill_manual(values = colourPaletteGroups, name = \"\") + \n  geom_stratum(width = 1/12, fill = \"pink\", color = \"orchid4\", linewidth = 1.2) +\n  #geom_text(stat = \"stratum\", aes(label = after_stat(stratum))) +\n  theme_void() + theme(legend.position = \"top\")\n\n\n\n\nEach stratum (pink box) represents the number of clusters set from two (far left) to six (far right). These clusters were estimated based on the distances in CA score space where the variables were abstract constructs, which we termed feeling and conviction. That aside, we can see from this alluvial plot which colour groupings are close toegther in this space, and when the split in each cluster occurs. Following Yellows, Purples, Greens and Colorful (which from the start we saw were all closely related with Positive sentiments), when we force the algorithm to choose five clusters, Yellows & Greens separate from Purples & Colorful, whcih by looking at the asymmetric biplot makes sense, despite the clear close association between the four colour groups in the sentiment space, the further subsetting splits according to the maximum distance in this space.\nIf we really want ro choose an appropriate number of clusters then we can use the total within cluster sums of squares (SS), which we’d like to minimize!\n\n## \"best\" representation using a rather 'adhoc'\n## total within SS\nbarplot(c(k2$tot.withinss,k3$tot.withinss,k4$tot.withinss,\n          k5$tot.withinss, k6$tot.withinss),\n        names = paste(2:6,\" clusters\"))\n\n\n\n\nThis is a rather ‘ad hoc’ method, but from the barplot we cannot see much relative tangible reduction in SS after three (maybe four) clusters. So, let’s look at these below.\n\nfviz_cluster(k3, data = data) + theme_bw()\n\n\n\n\nMakes sense based on even our initial CA biplot! Alternatively, we cn use HCPC, which performs agglomerative hierarchical clustering on CA results.\n\nhcpc &lt;- HCPC(coa, cluster.CA = \"rows\", nb.clust = 3)\n\n\n\n\n\n\n\n\n\nplot(hcpc,choice = \"3D.map\")\n\n\n\nplot(hcpc,choice = \"tree\")"
  },
  {
    "objectID": "colour_sentiments.html#footnotes",
    "href": "colour_sentiments.html#footnotes",
    "title": "4  Colour Sentiments",
    "section": "",
    "text": "important to note that these are abstract constructs!↩︎"
  },
  {
    "objectID": "data.html#the-lore-dataset",
    "href": "data.html#the-lore-dataset",
    "title": "1  The data!",
    "section": "1.1 The Lore dataset",
    "text": "1.1 The Lore dataset\nThe album_info_metadata.xlsx file includes the fan lore: sentiment, message, keywords, muse, colour meaning, notes, secret messages, colour mentions and their meanings (between positive, negative and neutral). While building the lore dataset, we realized that the mention of colours had more nuanced meaning than just a dicotomial division between “positive” or “negative”.\nTake the lyrics:\n\nDrowning in the Blue Nile, he sent me ‘Downtown Lights’\nYou cinephile in black and white, all those plot twists and dynamite*\nMy old blue jeans\nI stratch your head, you fall asleep, like a tattoed golden retriever\n\nTo us, the examples above show usage of colour as a purely discriptive adjective classifying a noun; there is no positive or negative feeling added in the qualifier, which contrasts to these examples:\n\nWe’re so sad, we paint the town blue (negative)\nThe rest of the world was black and white but we were in screaming colour (negative)\nI searched aurora borealis green (positive)\nIt’s like your eyes are liquor, it’s like your body is gold (positive)\n\nTherefore, the album_info_metadata_neutral.xlsx file is a slight improvement from the original lore with posivive and/or negative being replaced by neutral where it felt appropriated.\nThe sentiments were chosen from a list of feelings compiled by the Hoffman Institute Foundation (May/2015 review). Soon it was realized that a single sentiment was not enough to completely differentiate between songs and the message and keywords were also created to add more information to single out a song. For example, while Tim McGraw and Back to December both have the overall nostalgic feeling, the first carries a falling in love message, while the latter is about longing. Likewise, Tim McGraw keywords are romantic, first love, country music, while Back to December keywords are breakup, regretful, heartbreak.\n\nallSongsMetadata &lt;- readxl::read_excel(\"raw_data/album_info_metadata.xlsx\")[,1:29]\nallSongsMetadata \n\n# A tibble: 241 × 29\n   album_name     ep    album_release       track_number track_name sentiment_MK\n   &lt;chr&gt;          &lt;lgl&gt; &lt;dttm&gt;                     &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;       \n 1 evermore       FALSE 2020-12-11 00:00:00           13 marjorie   longing     \n 2 Midnights      FALSE 2022-10-21 00:00:00            4 Snow On T… peaceful    \n 3 Midnights      FALSE 2022-10-21 00:00:00           22 Snow On T… peaceful    \n 4 THE TORTURED … FALSE 2024-04-19 00:00:00           17 The Black… sad         \n 5 folklore       FALSE 2020-07-24 00:00:00            2 cardigan   melancholic \n 6 THE TORTURED … FALSE 2024-04-19 00:00:00           12 loml       sad         \n 7 Lover          FALSE 2019-08-23 00:00:00           18 Daylight   hopeful     \n 8 Speak Now (Ta… FALSE 2023-07-07 00:00:00           22 Timeless … nostalgic   \n 9 1989 (Taylor'… FALSE 2023-10-27 00:00:00            4 Out Of Th… anxious     \n10 reputation     FALSE 2017-11-10 00:00:00            5 Delicate   vulnerable  \n# ℹ 231 more rows\n# ℹ 23 more variables: message_MK &lt;chr&gt;, keywords_MK &lt;chr&gt;, Column1 &lt;dbl&gt;,\n#   muse_MK &lt;chr&gt;, colour_lyric_MK &lt;chr&gt;, colour_meaningMK &lt;chr&gt;,\n#   colour_MK &lt;chr&gt;, notes_MK &lt;chr&gt;, secret_message_MK &lt;chr&gt;, artist &lt;chr&gt;,\n#   featuring &lt;chr&gt;, bonus_track &lt;lgl&gt;, promotional_release &lt;dttm&gt;,\n#   single_release &lt;dttm&gt;, track_release &lt;dttm&gt;, danceability &lt;dbl&gt;,\n#   energy &lt;dbl&gt;, key &lt;dbl&gt;, loudness &lt;dbl&gt;, mode &lt;dbl&gt;, speechiness &lt;dbl&gt;, …\n\n\n\nallSongsMetadata &lt;- \"raw_data/album_info_metadata.xlsx\"\nallSongsMetadata &lt;- readxl::read_excel(allSongsMetadata, sheet = \"metadata\")\n\n#source(\"code/colourPalettes.r\")\n\ntaylorAlbumSongs&lt;- \"raw_data/taylor_album_songs.xlsx\"\ntaylorAlbumSongs&lt;- readxl::read_excel(\"raw_data/taylor_album_songs.xlsx\")\n\nsurpriseSongsDressColours &lt;- \"raw_data/surprise_songs.xlsx\"\nsurpriseSongsDressColours &lt;- readxl::read_excel(\"raw_data/surprise_songs.xlsx\")\n\n#Now, I need to select only one row per concert, which I can do by choosing only\n# the first song played in each concert\noneRowPerConcert &lt;- surpriseSongsDressColours %&gt;%\n  group_by(Date) %&gt;%\n  arrange(Date, Order) %&gt;%  \n  slice(1) %&gt;%\n  ungroup()\n\noneRowPerConcert$Date &lt;- as.Date(oneRowPerConcert$Date)\n\n\n## Dresses images\n\npathToDresscolours &lt;- \"dress_images/images_no_background\"\n\noneRowPerConcertWithImages &lt;- oneRowPerConcert %&gt;%\n  count(DressName) %&gt;%\n  mutate(\n    percentage = n / sum(n) * 100,\n    # Automatically build the path based on the dress name\n    imagePath = file.path(pathToDresscolours, paste0(DressName, \".png\"))\n  )\n\n\nrawcolourData &lt;- data.frame(\n    colour = trimws(unlist(strsplit(allSongsMetadata$colour_MK, \";\"))),\n    meaning = trimws(unlist(strsplit(allSongsMetadata$colour_meaningMK, \";\")))\n) %&gt;% filter(!is.na(colour) & !is.na(meaning))\n\ncolourSentimentScores &lt;- rawcolourData %&gt;%\n    mutate(\n        meaning = trimws(meaning),  \n        score = case_when(\n            tolower(meaning) == \"positive\" ~ 1,\n            tolower(meaning) == \"neutral\" ~ 0,\n            tolower(meaning) == \"negative\" ~ -1,\n            TRUE ~ NA_real_\n        )\n    )"
  },
  {
    "objectID": "data.html#sec-surp",
    "href": "data.html#sec-surp",
    "title": "1  The data!",
    "section": "1.2 Surprise Songs Data Set",
    "text": "1.2 Surprise Songs Data Set\nParallel to the development of the metadata (aka lore) database, a few details about each surprise song performance were noted down in the surprise_songs.xlsx data set. Each concert had a few rows, one per surprise song (Taylor performed two surprise songs in each of the concerts, the first one on the guitar and the second one on the piano). Besides the two regular surprise songs, she occasionally started mashing up songs in this acoustic set; although the first mashup happened in her second night in Ohio (July 1st, 2023), they became more common from the second night of her Melbourne concert (February 17th, 2024). Thus, three columns account for it: Mashups, with the options none, one or two; Mashup, with the name of the first song mashed up with Song title; and, Mashup2, with yet a third song that was mashed up with Song title and Mashup (in the case of Mashups = Two).\nBesides the song titles and mashups, the surprise songs data set includes the names of the city, state, country, stadium and dates in which she performed. Moreover, the name of the dress she was wearing is included in the column DressName, and its colour in descriptive terms is found on Colour1, its HEX formatting on ColourHex1, and its RGB formatting on ColourRGB1. As some dresses like Flamingo pink and Sunset orange are made up of an ombre of two colours, their name and codes are also found on Colour2, ColourHex2 and ColourRGB2. Lastly, other details are also included: who she was dating at the time in the Relationship column; which leg of the tour (First legs, European, Final leg), which night on that city, which instrument she played while singing said song, special guests in the audience, and notes for overall remarks such as: on July 9th, she sang Last Kiss as one the surprise songs, and that date is mentioned on the song.\n\n## reading in data\nsurpriseSongsDressColours &lt;-  readxl::read_excel(\"raw_data/surprise_songs.xlsx\", sheet = \"List\")\nsurpriseSongsDressColours$Date &lt;- as.Date(surpriseSongsDressColours$Date)\nsurpriseSongsDressColours\n\n# A tibble: 443 × 26\n   `Song title`         Mashups Mashup Mashup2 Guest City  State Country Stadium\n   &lt;chr&gt;                &lt;chr&gt;   &lt;chr&gt;  &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;  \n 1 mirrorball           None    &lt;NA&gt;   &lt;NA&gt;    &lt;NA&gt;  Glen… Ariz… US      State …\n 2 Tim McGraw           None    &lt;NA&gt;   &lt;NA&gt;    &lt;NA&gt;  Glen… Ariz… US      State …\n 3 State Of Grace       None    &lt;NA&gt;   &lt;NA&gt;    &lt;NA&gt;  Glen… Ariz… US      State …\n 4 this is me trying    None    &lt;NA&gt;   &lt;NA&gt;    &lt;NA&gt;  Glen… Ariz… US      State …\n 5 Our Song             None    &lt;NA&gt;   &lt;NA&gt;    &lt;NA&gt;  Las … Neva… US      Allegi…\n 6 Snow On The Beach    None    &lt;NA&gt;   &lt;NA&gt;    &lt;NA&gt;  Las … Neva… US      Allegi…\n 7 cowboy like me       None    &lt;NA&gt;   &lt;NA&gt;    Marc… Las … Neva… US      Allegi…\n 8 White Horse          None    &lt;NA&gt;   &lt;NA&gt;    &lt;NA&gt;  Las … Neva… US      Allegi…\n 9 Ours                 None    &lt;NA&gt;   &lt;NA&gt;    &lt;NA&gt;  Arli… Texas US      AT&T   \n10 Sad Beautiful Tragic None    &lt;NA&gt;   &lt;NA&gt;    &lt;NA&gt;  Arli… Texas US      AT&T   \n# ℹ 433 more rows\n# ℹ 17 more variables: Date &lt;date&gt;, DressName &lt;chr&gt;, Legs &lt;chr&gt;,\n#   Relationship &lt;chr&gt;, Start &lt;dttm&gt;, End &lt;dttm&gt;, Colour1 &lt;chr&gt;,\n#   ColourHex1 &lt;chr&gt;, ColourRGB1 &lt;chr&gt;, Colour2 &lt;chr&gt;, ColourHex2 &lt;chr&gt;,\n#   ColourRGB2 &lt;chr&gt;, `Night #` &lt;dbl&gt;, Order &lt;dbl&gt;, Instrument &lt;chr&gt;,\n#   `Special Annoucement` &lt;chr&gt;, Notes &lt;chr&gt;\n\n\n\n1.2.1 An overview of surprise song dresses across the whole tour\n\n## Need only consider first element of each concerts as the\n## same outfit was worn for all surprise songs\n## for anyone concert\noneRowPerConcert &lt;- surpriseSongsDressColours %&gt;%\n    group_by(Date) %&gt;%\n    arrange(Date, Order) %&gt;% \n    slice(1) %&gt;%\n    ungroup()\noneRowPerConcert\n\n# A tibble: 147 × 26\n   `Song title`         Mashups Mashup Mashup2 Guest City  State Country Stadium\n   &lt;chr&gt;                &lt;chr&gt;   &lt;chr&gt;  &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;  \n 1 mirrorball           None    &lt;NA&gt;   &lt;NA&gt;    &lt;NA&gt;  Glen… Ariz… US      State …\n 2 this is me trying    None    &lt;NA&gt;   &lt;NA&gt;    &lt;NA&gt;  Glen… Ariz… US      State …\n 3 Our Song             None    &lt;NA&gt;   &lt;NA&gt;    &lt;NA&gt;  Las … Neva… US      Allegi…\n 4 cowboy like me       None    &lt;NA&gt;   &lt;NA&gt;    Marc… Las … Neva… US      Allegi…\n 5 Sad Beautiful Tragic None    &lt;NA&gt;   &lt;NA&gt;    &lt;NA&gt;  Arli… Texas US      AT&T   \n 6 Death By A Thousand… None    &lt;NA&gt;   &lt;NA&gt;    &lt;NA&gt;  Arli… Texas US      AT&T   \n 7 Speak Now            None    &lt;NA&gt;   &lt;NA&gt;    &lt;NA&gt;  Tampa Flor… US      Raymon…\n 8 The Great War        None    &lt;NA&gt;   &lt;NA&gt;    Aaro… Tampa Flor… US      Raymon…\n 9 mad woman            None    &lt;NA&gt;   &lt;NA&gt;    &lt;NA&gt;  Tampa Flor… US      Raymon…\n10 Wonderland           None    &lt;NA&gt;   &lt;NA&gt;    &lt;NA&gt;  Hous… Texas US      NRG    \n# ℹ 137 more rows\n# ℹ 17 more variables: Date &lt;date&gt;, DressName &lt;chr&gt;, Legs &lt;chr&gt;,\n#   Relationship &lt;chr&gt;, Start &lt;dttm&gt;, End &lt;dttm&gt;, Colour1 &lt;chr&gt;,\n#   ColourHex1 &lt;chr&gt;, ColourRGB1 &lt;chr&gt;, Colour2 &lt;chr&gt;, ColourHex2 &lt;chr&gt;,\n#   ColourRGB2 &lt;chr&gt;, `Night #` &lt;dbl&gt;, Order &lt;dbl&gt;, Instrument &lt;chr&gt;,\n#   `Special Annoucement` &lt;chr&gt;, Notes &lt;chr&gt;"
  },
  {
    "objectID": "viz.html#the-most-worn-looks",
    "href": "viz.html#the-most-worn-looks",
    "title": "2  Visualizing the data",
    "section": "The most worn looks",
    "text": "The most worn looks\n\n\nCode\n## map hex colour to outfit\ndressColorMapping &lt;- unique(surpriseSongsDressColours %&gt;% select(DressName, ColourHex1))\ncolorPaletteDresses &lt;- setNames(dressColorMapping$ColourHex1, dressColorMapping$DressName)\npathToDressColours &lt;- \"dress_images/images_no_background/\"\n## map outfits to the corresponding images\noneRowPerConcert %&gt;%\n    count(DressName) %&gt;%\n    mutate(\n        percentage = n / sum(n) * 100,\n        imagePath = case_when(\n            DressName == \"Pink\" ~paste0(pathToDressColours, \"Pink.png\"),\n            DressName == \"Green\" ~paste0(pathToDressColours, \"Green.png\"),\n            DressName == \"Yellow\" ~paste0(pathToDressColours, \"Yellow.png\"),\n            DressName == \"Blue\" ~paste0(pathToDressColours, \"Blue.png\"),\n            DressName == \"Flamingo pink\" ~ paste0(pathToDressColours,\"Flamingo Pink.png\"),\n            DressName == \"Ocean blue\" ~ paste0(pathToDressColours,\"Ocean Blue.png\"),\n            DressName == \"Sunset orange\" ~ paste0(pathToDressColours,\"Sunset Orange.png\"),\n            DressName == \"Cotton candy\" ~paste0(pathToDressColours, \"Cotton Candy.png\"),\n            DressName == \"Blurple\" ~paste0(pathToDressColours, \"Blurple.png\"),\n            DressName == \"Grapefruit\" ~ paste0(pathToDressColours,\"Grapefruit.png\"),\n            DressName == \"Popsicle\" ~ paste0(pathToDressColours,\"Popsicle.png\"),\n            TRUE ~ NA_character_\n        )) -&gt; outfits\n\n## barchart\nggplot(outfits, aes(x = reorder(DressName, -n), y = n, fill = DressName)) +\n    geom_bar(stat = \"identity\", width = 0.8) +  \n    geom_image(\n        aes(image = imagePath, y = n),  \n        size = 0.15,                    \n        by = \"height\"                    \n    ) +\n    geom_text(\n        aes(y = n + 3.8, label = paste0(n, \"\\n(\", round(percentage, 1), \"%)\")),  \n        vjust = 0,  \n        color = \"black\",\n        size = 4\n    ) +\n    scale_fill_manual(values = colorPaletteDresses) +\n    theme_minimal() +\n    labs(title = \"\", x = \"\", y = \"\") +\n    theme(\n        axis.text.x = element_text(angle = 45, hjust = 1, size = 14),\n        axis.text.y = element_text(size = 14),\n        plot.title = element_text(hjust = 0.5, size = 16),\n        axis.title.x = element_blank(),\n        axis.title.y = element_blank(),\n        legend.position = \"none\"\n    ) + ylim(0, 35)"
  },
  {
    "objectID": "viz.html#eras-outfits-and-special-events",
    "href": "viz.html#eras-outfits-and-special-events",
    "title": "2  Visualizing the data",
    "section": "Eras’ Outfits and Special Events",
    "text": "Eras’ Outfits and Special Events\nAlthough the first legs (US, Latin America and Asia/Oceania) had only the four original colours to choose from, the European leg and the final, North American legs, had their own set of colours that did not appear anywhere else in the tour. It seemed that Swift had a love story with certain shades depending on which continent she was enchanting.\n\n\nCode\n# First, find the first date for each dress\ndress_first_appearance &lt;- oneRowPerConcert %&gt;%\n  group_by(DressName) %&gt;%\n  summarize(FirstAppearance = min(Date)) %&gt;%\n  arrange((FirstAppearance))\n\n# Convert DressName to a factor with ordered levels\noneRowPerConcert$DressName &lt;- factor(oneRowPerConcert$DressName, \n                                     levels = dress_first_appearance$DressName)\n\nmax_dress_level &lt;- length(unique(oneRowPerConcert$DressName))\n\n\n\n# Create the main timeline plot\nmain_plot &lt;- ggplot(oneRowPerConcert, aes(x = Date, y = DressName, colour = ColourHex1)) +\n  geom_point(size = 4, alpha = 1) +\n  scale_colour_identity() +\n  theme_minimal() +\n  labs(x = \"\", y = \"\") +\n  geom_rect(aes(xmin = as.Date(\"2023-08-28\"), xmax = as.Date(\"2023-11-08\"),\n                ymin = -Inf, ymax = Inf), fill = \"gray\", alpha = 0.01, colour = NA) +\n  geom_rect(aes(xmin = as.Date(\"2023-11-27\"), xmax = as.Date(\"2024-02-06\"),\n                ymin = -Inf, ymax = Inf), fill = \"gray\", alpha = 0.01, colour = NA) +  \n  geom_rect(aes(xmin = as.Date(\"2024-03-10\"), xmax = as.Date(\"2024-05-08\"),\n                ymin = -Inf, ymax = Inf), fill = \"gray\", alpha = 0.01, colour = NA) +\n  geom_rect(aes(xmin = as.Date(\"2024-08-21\"), xmax = as.Date(\"2024-10-17\"),\n                ymin = -Inf, ymax = Inf), fill = \"gray\", alpha = 0.01, colour = NA) +\n  # Vertical lines for the key events\n  geom_vline(xintercept = as.Date(\"2024-05-09\"), linetype = \"dashed\", colour = \"black\") +\n  geom_vline(xintercept = as.Date(\"2023-03-17\"), linetype = \"dashed\", colour = \"black\") +\n  geom_vline(xintercept = as.Date(\"2024-10-18\"), linetype = \"dashed\", colour = \"black\") +\n  geom_vline(xintercept = as.Date(\"2023-08-24\"), linetype = \"dashed\", colour = \"black\") +\n  geom_vline(xintercept = as.Date(\"2024-02-07\"), linetype = \"dashed\", colour = \"black\") +\n  geom_vline(xintercept = as.Date(\"2024-04-16\"), linetype = \"solid\", colour = \"darkgray\", size=2) +\n  geom_vline(xintercept = as.Date(\"2023-07-07\"), linetype = \"solid\", colour = \"purple\", size=2) +\n  geom_vline(xintercept = as.Date(\"2023-10-27\"), linetype = \"solid\", colour = \"blue\", size=2) +\n\n  annotate(\"text\", x = as.Date(\"2024-05-09\"), y = max_dress_level, \n           label = \"Europeᵃ\", colour = \"black\", angle = -90, vjust = -0.5, , size = 6, lineheight = 0.6) +\n  annotate(\"text\", x = as.Date(\"2023-03-17\"), y = max_dress_level, \n           label = \"United\\nStatesᵃ\", colour = \"black\", angle = -90, vjust = -0.2, , size = 6, lineheight = 0.6) +\n  annotate(\"text\", x = as.Date(\"2024-10-18\"), y = max_dress_level, \n           label = \"North\\nAmericaᵃ\", colour = \"black\", angle = -90, vjust = -0.2, , size = 6, lineheight = 0.6) +\n  annotate(\"text\", x = as.Date(\"2023-08-24\"), y = max_dress_level, \n           label = \"Latin\\nAmericaᵃ\", colour = \"black\", angle = -90, vjust = -0.2, , size = 6, lineheight = 0.6) +\n  annotate(\"text\", x = as.Date(\"2024-02-07\"), y = max_dress_level, \n           label = \"Asia/\\nOceaniaᵃ\", colour = \"black\", angle = -90, vjust = -0.2, , size = 6, lineheight = 0.6) +\n  annotate(\"text\", x = as.Date(\"2024-04-16\"), y = max_dress_level, \n           label = \"TTPDᵇ\", colour = \"darkgray\", angle = -90, vjust = -0.5, , size = 6, lineheight = 0.6,\n           fontface = \"bold\") +\n  annotate(\"text\", x = as.Date(\"2023-07-07\"), y = max_dress_level, \n           label = \"Speak Now\\nTVᵇ\", colour = \"purple\", angle = -90, vjust = -0.2, , size = 6, lineheight = 0.6) +\n  annotate(\"text\", x = as.Date(\"2023-10-27\"), y = max_dress_level, \n           label = \"1989\\nTVᵇ\", colour = \"blue\", angle = -90, vjust = -0.2, , size = 6, lineheight = 0.6) +\n  scale_x_date(date_labels = \"%b %Y\", date_breaks = \"3 months\") +\n  theme(\n    axis.text.x = element_text(angle = 0, hjust = 1, size = 16),\n    axis.text.y = element_blank(),\n    axis.ticks.y = element_blank(),\n    plot.title = element_text(hjust=0.5, size = 14, margin = margin(b = 20), face = \"bold\"),\n    plot.margin = margin(t = -7, r = 0, b = 10, l = 0),\n    text = element_text(colour = \"black\", , size = 16)\n  )\n\nsource(\"code/colourPalettes.r\")\n# Create dress count plot (to go on the right side)\n# Ensure the dress order matches exactly with the main plot\ndress_levels &lt;- levels(factor(oneRowPerConcert$DressName))\noneRowPerConcertWithImages$DressName &lt;- factor(oneRowPerConcertWithImages$DressName, levels = dress_levels)\n\ncount_plot &lt;- ggplot(oneRowPerConcertWithImages, aes(x = n, y = DressName, fill = DressName)) +\n  geom_bar(stat = \"identity\", width = 0.8) +\n  geom_image(\n    aes(image = imagePath, x = n),  \n    size = 0.09,                    \n    nudge_x = 0,\n    by = \"height\"                    \n  ) +\n  geom_text(\n    aes(x = n + 3, label = paste0(n, \" (\", round(percentage, 1), \"%) - \", DressName)),  # Added dress name\n    hjust = 0,\n    nudge_x = 3,\n    colour = \"black\",\n    size = 6,\n    \n  ) +\n  scale_fill_manual(values = colourPaletteDresses) +\n  theme_minimal() +\n  labs(title = \"\", x = \"\", y = \"\") +\n  theme(\n    axis.text = element_blank(),\n    axis.ticks = element_blank(),  # Remove any remaining ticks\n    plot.title = element_text(hjust = 0.5, size = 12),\n    legend.position = \"none\",\n    plot.margin = margin(t = -7, r = 0, b = 10, l = 0),\n    text = element_text(colour = \"black\", , size = 16)\n  ) +\n  xlim(0, 65)   # Increased limit to accommodate longer text with dress names\n\n# Merge the plots using cowplot with adjusted widths\nmerged_plot &lt;- plot_grid(\n  count_plot, main_plot,\n  ncol = 2,\n  align = \"h\",\n  axis = \"tb\",\n  rel_widths = c(2, 3)  # Increased count plot width to accommodate longer text\n)\n\n\nmerged_plot"
  },
  {
    "objectID": "viz.html#surprise-song-color-groups",
    "href": "viz.html#surprise-song-color-groups",
    "title": "2  Visualizing the data",
    "section": "Surprise song color groups",
    "text": "Surprise song color groups\n\n\nCode\nsurpriseSongsDressColours$groupName &lt;- sapply(surpriseSongsDressColours$DressName, function(color) {\n  if (color %in% c(\"Pink\", \"Flamingo pink\")) return(\"reds\")\n  if (color %in% c(\"Green\")) return(\"greens\")\n  if(color %in% c(\"Yellow\", \"Sunset orange\")) return(\"yellows\")\n  if (color %in% c(\"Ocean blue\", \"Blue\", \"Blurple\")) return (\"blues\")\n  if (color %in% c(\"Popsicle\", \"Cotton candy\", \"Grapefruit\")) return (\"colorful\")\n  return(\"Neutral\")\n})\n\nsongs_with_single_color_group &lt;- surpriseSongsDressColours %&gt;%\n  group_by(`Song title`) %&gt;%\n  summarize(\n    total_performances = n(),\n    unique_color_groups = n_distinct(groupName),\n    color_group = first(groupName) \n  ) %&gt;%\n  filter(unique_color_groups == 1, total_performances &gt; 1) %&gt;%\n  arrange(desc(total_performances))\n\nsingle_color_performances &lt;- surpriseSongsDressColours %&gt;%\n    filter(`Song title` %in% songs_with_single_color_group$`Song title`)\n\n## pics\nblues &lt;- paste(\"dress_images/images_no_background/\", c(\"blue\", \"Ocean Blue\", \"Blurple\"), \".png\", sep = \"\")\nreds &lt;- paste(\"dress_images/images_no_background/\", c(\"pink\", \"Flamingo Pink\"), \".png\", sep = \"\")\nyellows &lt;- paste(\"dress_images/images_no_background/\", c(\"yellow\", \"Sunset Orange\"), \".png\", sep = \"\")\n\ncoords &lt;- circleProgressiveLayout(table(single_color_performances$groupName),\n                                  sizetype = 'area')\ncoords$id &lt;- names(table(single_color_performances$groupName))\ndf.gg &lt;- circleLayoutVertices(coords, npoints = 8, id = 4)\nsnames &lt;- single_color_performances %&gt;% select('Song title', groupName) %&gt;%\n    group_by(`Song title`) %&gt;% mutate(count = n()) %&gt;% ungroup() |&gt; unique()\nset.seed(1984) ## for jitter repel\nplot &lt;- ggplot() + theme_void() +\n    ## blues\n    geom_polygon(data = df.gg[df.gg$id == \"blues\",], aes(x = x, y = y),\n                 fill = \"#0000FF\", alpha = 0.05) +\n    geom_text_repel(aes(x = coords$x[1], \n                        y = coords$y[1], \n                        label = snames$`Song title`[snames$groupName == \"blues\"]),\n                    col = \"#0000FF\", nudge_y = -1.1, nudge_x = 0.1, segment.color = NA,\n                    size = 1.5*snames$count[snames$groupName == \"blues\"], box.padding = 0.1) +\n    ## reds\n    geom_polygon(data = df.gg[df.gg$id == \"reds\",], aes(x = x, y = y),\n                 fill = \"#FF0000\", alpha = 0.05)  +\n    geom_text_repel(aes(x = coords$x[2], \n                        y = coords$y[2], \n                        label = snames$`Song title`[snames$groupName == \"reds\"]),\n                    col = \"#FF0000\", nudge_y = -0.9, nudge_x = 0.1, segment.color = NA,\n                    size = 1.5*snames$count[snames$groupName == \"reds\"], box.padding = 0.1) +\n    ## yellows\n    geom_polygon(data = df.gg[df.gg$id == \"yellows\",], aes(x = x, y = y),\n                 fill = \"#FFD700\", alpha = 0.05)  +\n    geom_text_repel(aes(x = coords$x[3], \n                        y = coords$y[3], \n                        label = snames$`Song title`[snames$groupName == \"yellows\"]),\n                    col = \"#FFD700\", nudge_y = 1.4, nudge_x = 0, segment.color = NA,\n                    size = 1.5*snames$count[snames$groupName == \"yellows\"], box.padding = 0.1)\n\n## image sizes relative to\n## table(single_color_performances$DressName, single_color_performances$groupName)\nset.seed(1984) ## for jitter repel\nggdraw() +\n    draw_plot(plot) +\n    draw_image(blues[1], -0.37, 0.23, scale = 0.5/3) +\n    draw_image(blues[2],  -0.2, 0.32, scale = 0.8/3) +\n    draw_image(blues[3],  -0.07, 0.26, scale = 0.4/3) +\n    draw_image(reds[1], 0.1, 0.27, scale = 0.8/3) +\n    draw_image(reds[2],  0.3, 0.33, scale = 0.7/3) +\n    draw_image(yellows[1], -0.1, -0.25, scale = 0.7/3) +\n    draw_image(yellows[2],  0.1, -0.3, scale = 1.1/3)"
  },
  {
    "objectID": "outfit_transitions.html#a-chi2-test-for-the-transition-counts",
    "href": "outfit_transitions.html#a-chi2-test-for-the-transition-counts",
    "title": "3  Are the surprise song outfits random?",
    "section": "3.1 A \\(\\chi^2\\)-test for the transition counts",
    "text": "3.1 A \\(\\chi^2\\)-test for the transition counts\nLikely, the first standard hypothesis test you think of for count/contingency data is the \\(\\chi^2\\)-test (or the chi-squared test). Essentially, this works by testing for equal transition rates (if the outfit choices were completely random we’d expect equal numbers of transitions between the outfits); Slightly more formally,\n\\(H_0 = \\text{row outfits independent of column outfits}\\) vs. \\(H_1 = \\text{row outfits not independent of column outfits}\\).\n\n## first leg\nfirst_leg |&gt; transitions() |&gt; chisq.test()\n\n\n    Pearson's Chi-squared test\n\ndata:  transitions(first_leg)\nX-squared = 10.259, df = 9, p-value = 0.33\n\n## europe leg\nmid_leg |&gt; transitions() |&gt; chisq.test()\n\n\n    Pearson's Chi-squared test\n\ndata:  transitions(mid_leg)\nX-squared = 19.554, df = 4, p-value = 0.0006115\n\n## final leg\nfinal_leg |&gt; transitions() |&gt; chisq.test()\n\n\n    Pearson's Chi-squared test\n\ndata:  transitions(final_leg)\nX-squared = 17.337, df = 16, p-value = 0.3641\n\n\n\n\n\n\nTable 3.1: Summary of the chi-squared tests on the transition matricies for each leg of the Eras tour.\n\n\n\nChi-squared statistic\nDegrees of freedom\np-vlaue\n\n\n\n\nFirst Leg\n10.259\n9\n0.330\n\n\nEuropean Leg\n19.554\n4\n0.001\n\n\nFinal Leg\n17.337\n16\n0.364\n\n\n\n\n\n\nTherefore, if our \\(\\chi^2\\) assumptions were met we might infer that there’s some evidence against the outfits for the European leg being random.\n\n\n\n\n\nChi-squared distribution under the NULL hypothesis for each leg along with the observed chi-squared statistic in purple."
  },
  {
    "objectID": "outfit_transitions.html#a-randomisation-test",
    "href": "outfit_transitions.html#a-randomisation-test",
    "title": "3  Are the surprise song outfits random?",
    "section": "3.2 A randomisation test",
    "text": "3.2 A randomisation test\nIf we’re not happy that our parametric assumptions are met then we can (often) fall back on simple resampling methods; basically simulating what would happen under chance alone and then comparing how our observed situation stack up!\nTo begin with let’s use the \\(\\chi^2\\)-squared statistic to represent the transition matrix we observed for each leg (it is a valid metric comparing between what we expected under independence and what we observed). By using a randomisation test we can build up a sampling distribution of this chosen metric that represent what would happen under chance alone (i.e., without any assumptions about the shape of this distribution). Our observed statistics in this case are given in the first column of Table 3.1.\n\n## create a function for the randomisation test using chi-sq\n## on the transition matrix, using a for loop just bc\n\nrandomisation &lt;- function(data, nreps = 1000, seed = 1984){\n  sampling_dist &lt;- numeric(nreps)\n  set.seed(seed) \n  for (i in 1:nreps) {\n   sampling_dist[i] &lt;- suppressWarnings(sample(data) |&gt; \n                                          transitions() |&gt; \n                                          chisq.test())$statistic\n  }\nreturn(sampling_dist)\n}\n\nCalculating a p-value (note they’re all pretty much the same as above!).\n\n## first leg\nnull_first &lt;- randomisation(first_leg)\nmean(null_first &gt;= (first_leg |&gt; transitions() |&gt; chisq.test())$statistic)\n\n[1] 0.336\n\n## European leg\nnull_mid &lt;- randomisation(mid_leg)\nmean(null_mid &gt;= (mid_leg |&gt; transitions() |&gt; chisq.test())$statistic)\n\n[1] 0.001\n\n## Final leg\nnull_final &lt;- randomisation(final_leg)\nmean(null_final &gt;= (final_leg |&gt; transitions() |&gt; chisq.test())$statistic)\n\n[1] 0.322\n\n\n\n\n\n\n\nSampling distribution of the test statistic (the chi-squared statistic) under the NULL hypothesis for each leg along with the observed test statistic in purple.\n\n\n\n\nBut, we can actually use any metric we like in a randomisation test! For our example, the \\(\\chi^2\\) is a nice (distance) statistic because it considers all the transitions, but if we were particularly interested in, say, a particular transition (e.g., Yellow \\(\\rightarrow\\) Pink for the first leg) we could look at those instead.\n\\(H_0 = \\text{A particular transition occured at random}\\)\nvs. \n\\(H_1 = \\text{A particular transition occured fewer or more times than expected}\\).\n[Note: than expected means than was expected under chance alone.]\n\n## create a new function for the randomisation test using the \n## numbers of a particular transition (from --&gt; to)\n\nrandomisation &lt;- function(data, from = \"Yellow\", to = \"Pink\", \n                          nreps = 1000, seed = 1984){\n  sampling_dist &lt;- numeric(nreps)\n  set.seed(seed) \n  for (i in 1:nreps) {\n   sampling_dist[i] &lt;- (sample(data) |&gt; transitions())[from, to]\n  }\nreturn(sampling_dist)\n}\n\nCalculating a two-sided p-value.\n\n## first leg, Yellow --&gt; Pink (default)\nnull_first &lt;- randomisation(first_leg)\nobs_first &lt;- (first_leg |&gt; transitions())[\"Yellow\", \"Pink\"]\nmean(abs(null_first - mean(null_first)) &gt;= abs(obs_first - mean(null_first)))\n\n[1] 0.199\n\n## European leg, Sunset orange --&gt; Flamingo pink\nnull_mid &lt;- randomisation(mid_leg, from = \"Sunset orange\", to = \"Flamingo pink\")\nobs_mid &lt;- (mid_leg |&gt; transitions())[\"Sunset orange\", \"Flamingo pink\"]\nmean(abs(null_mid - mean(null_mid)) &gt;= abs(obs_mid - mean(null_mid)))\n\n[1] 0.766\n\n## Final leg, Blurple --&gt; Blurple\nnull_final &lt;- randomisation(final_leg, from = \"Blurple\", to = \"Blurple\")\nobs_final &lt;- (final_leg |&gt; transitions())[\"Blurple\", \"Blurple\"]\nmean(abs(null_final - mean(null_final)) &gt;= abs(obs_final - mean(null_final)))\n\n[1] 0.644\n\n\n\n\n\n\n\nSampling distribution of the test statistic (the number of times a particular transition occured) under the NULL hypothesis for each leg along with the observed test statistic in purple.\n\n\n\n\nIn each case, no evidence to suggest we see the particular transitions more or less frequently than would be expected under the NULL hypothesis of chance alone. (Note the transitions were chosen arbitrarily)"
  },
  {
    "objectID": "outfit_transitions.html#a-likelihood-ratio-test",
    "href": "outfit_transitions.html#a-likelihood-ratio-test",
    "title": "3  Are the surprise song outfits random?",
    "section": "3.3 A likelihood ratio test",
    "text": "3.3 A likelihood ratio test\nWhat about using a model based approach? If the outfits were random (given the choices) then we’d expect each to occur independently of one another (i.e., the chance of one outfit is independent of any other).\nLet’s consider the first leg, defining the events mathematically we let \\(\\{X_1, X_2, \\ldots, X_n\\}\\) be the outfits taking values in \\(\\{\\text{Blue}, \\text{Green}, \\text{Pink}, \\text{Yellow}\\}\\) (i.e., four possible categories).\nIf the outfits were independent then we can write the likelihood as\n\\[L_0(p; x) = \\prod_{t=1}^{n} P(X_t = x_t) = \\prod_{j=1}^{4} p_j^{n_j}\\].\nHere \\(p_j\\) is the probability of observing category \\(j\\), \\(n_j\\) is the number of times category \\(j\\) appears from \\(t=2\\) to \\(n\\), and \\(\\sum_{j=1}^{k} p_j = 1\\). The log-likelihood is therefore \\[\\log L_0(p;x) = \\sum_{t=2}^{n} \\log p_{x_t} = \\sum_{j=1}^{4} n_j \\log p_j\\].\nCalculating this in R step-by-step\n\nn &lt;- length(first_leg)\nn\n\n[1] 81\n\nk &lt;- length(unique(first_leg))\nk\n\n[1] 4\n\nchain &lt;- as.factor(first_leg)\nchain\n\n [1] Pink   Green  Pink   Green  Green  Pink   Yellow Pink   Green  Yellow\n[11] Pink   Green  Green  Pink   Yellow Pink   Green  Yellow Pink   Yellow\n[21] Green  Yellow Green  Pink   Pink   Green  Yellow Pink   Green  Yellow\n[31] Pink   Yellow Yellow Pink   Green  Pink   Pink   Yellow Yellow Pink  \n[41] Green  Pink   Pink   Yellow Pink   Pink   Pink   Pink   Yellow Green \n[51] Blue   Blue   Pink   Green  Yellow Blue   Pink   Yellow Yellow Blue  \n[61] Green  Blue   Yellow Green  Blue   Yellow Pink   Green  Yellow Pink  \n[71] Blue   Pink   Blue   Yellow Green  Yellow Green  Pink   Pink   Yellow\n[81] Blue  \nLevels: Blue Green Pink Yellow\n\np_indep &lt;- table(chain) / n\np_indep ## independent probabilities\n\nchain\n     Blue     Green      Pink    Yellow \n0.1111111 0.2469136 0.3580247 0.2839506 \n\np_indep[as.integer(chain)] ## probabilities of each element as they occur\n\nchain\n     Pink     Green      Pink     Green     Green      Pink    Yellow      Pink \n0.3580247 0.2469136 0.3580247 0.2469136 0.2469136 0.3580247 0.2839506 0.3580247 \n    Green    Yellow      Pink     Green     Green      Pink    Yellow      Pink \n0.2469136 0.2839506 0.3580247 0.2469136 0.2469136 0.3580247 0.2839506 0.3580247 \n    Green    Yellow      Pink    Yellow     Green    Yellow     Green      Pink \n0.2469136 0.2839506 0.3580247 0.2839506 0.2469136 0.2839506 0.2469136 0.3580247 \n     Pink     Green    Yellow      Pink     Green    Yellow      Pink    Yellow \n0.3580247 0.2469136 0.2839506 0.3580247 0.2469136 0.2839506 0.3580247 0.2839506 \n   Yellow      Pink     Green      Pink      Pink    Yellow    Yellow      Pink \n0.2839506 0.3580247 0.2469136 0.3580247 0.3580247 0.2839506 0.2839506 0.3580247 \n    Green      Pink      Pink    Yellow      Pink      Pink      Pink      Pink \n0.2469136 0.3580247 0.3580247 0.2839506 0.3580247 0.3580247 0.3580247 0.3580247 \n   Yellow     Green      Blue      Blue      Pink     Green    Yellow      Blue \n0.2839506 0.2469136 0.1111111 0.1111111 0.3580247 0.2469136 0.2839506 0.1111111 \n     Pink    Yellow    Yellow      Blue     Green      Blue    Yellow     Green \n0.3580247 0.2839506 0.2839506 0.1111111 0.2469136 0.1111111 0.2839506 0.2469136 \n     Blue    Yellow      Pink     Green    Yellow      Pink      Blue      Pink \n0.1111111 0.2839506 0.3580247 0.2469136 0.2839506 0.3580247 0.1111111 0.3580247 \n     Blue    Yellow     Green    Yellow     Green      Pink      Pink    Yellow \n0.1111111 0.2839506 0.2469136 0.2839506 0.2469136 0.3580247 0.3580247 0.2839506 \n     Blue \n0.1111111 \n\np_indep[as.integer(chain)] |&gt; log() ## log probabilities of each element as they occur\n\nchain\n     Pink     Green      Pink     Green     Green      Pink    Yellow      Pink \n-1.027153 -1.398717 -1.027153 -1.398717 -1.398717 -1.027153 -1.258955 -1.027153 \n    Green    Yellow      Pink     Green     Green      Pink    Yellow      Pink \n-1.398717 -1.258955 -1.027153 -1.398717 -1.398717 -1.027153 -1.258955 -1.027153 \n    Green    Yellow      Pink    Yellow     Green    Yellow     Green      Pink \n-1.398717 -1.258955 -1.027153 -1.258955 -1.398717 -1.258955 -1.398717 -1.027153 \n     Pink     Green    Yellow      Pink     Green    Yellow      Pink    Yellow \n-1.027153 -1.398717 -1.258955 -1.027153 -1.398717 -1.258955 -1.027153 -1.258955 \n   Yellow      Pink     Green      Pink      Pink    Yellow    Yellow      Pink \n-1.258955 -1.027153 -1.398717 -1.027153 -1.027153 -1.258955 -1.258955 -1.027153 \n    Green      Pink      Pink    Yellow      Pink      Pink      Pink      Pink \n-1.398717 -1.027153 -1.027153 -1.258955 -1.027153 -1.027153 -1.027153 -1.027153 \n   Yellow     Green      Blue      Blue      Pink     Green    Yellow      Blue \n-1.258955 -1.398717 -2.197225 -2.197225 -1.027153 -1.398717 -1.258955 -2.197225 \n     Pink    Yellow    Yellow      Blue     Green      Blue    Yellow     Green \n-1.027153 -1.258955 -1.258955 -2.197225 -1.398717 -2.197225 -1.258955 -1.398717 \n     Blue    Yellow      Pink     Green    Yellow      Pink      Blue      Pink \n-2.197225 -1.258955 -1.027153 -1.398717 -1.258955 -1.027153 -2.197225 -1.027153 \n     Blue    Yellow     Green    Yellow     Green      Pink      Pink    Yellow \n-2.197225 -1.258955 -1.398717 -1.258955 -1.398717 -1.027153 -1.027153 -1.258955 \n     Blue \n-2.197225 \n\nll0 &lt;- p_indep[as.integer(chain)] |&gt; log() |&gt; sum() ## log likelihood\nll0\n\n[1] -106.4928\n\n\nNow, what about the likelihood if we assume the sequence of outfits is a first-order Markov chain (i.e., the current outfit \\(X_t\\) depends on the previous one \\(X_{t-1}\\)):\n\\[P(X_t = x_t \\mid X_{t-1} = x_{t-1}) = P_{x_{t-1}, x_t}.\\]\nHere \\(P_{i,j}\\) is the probability of transitioning from state \\(i\\) to state \\(j\\), again with \\(\\sum_{j=1}^{k} P_{i,j} = 1 \\quad \\text{for all } i\\). We can write the likelihood as\n\\[L_1(p;x_t|x_{t-1}) = \\prod_{t=2}^{n} P(X_t = x_t \\mid X_{t-1} = x_{t-1}) = \\prod_{i=1}^{k} \\prod_{j=1}^{k} P_{i,j}^{N_{i,j}}\\]\nWhere \\(N_{i,j}\\) is the number of transitions from state \\(i\\) to state \\(j\\). The log-likelihood is then\n\\[\\log(L_1(p;x_t|x_{t-1})) = \\sum_{t=2}^{n} \\log (P_{x_{t-1}, x_t}) = \\sum_{i=1}^{k} \\sum_{j=1}^{k} N_{i,j} \\log (P_{i,j})\\]\nCalculating this in R step-by-step\n\n## transition probability matrix\ntm &lt;- prop.table(transitions(first_leg), 1) ## over rows\ntm\n\n        \n               Blue      Green       Pink     Yellow\n  Blue   0.12500000 0.12500000 0.37500000 0.37500000\n  Green  0.15000000 0.10000000 0.35000000 0.40000000\n  Pink   0.06896552 0.37931034 0.24137931 0.31034483\n  Yellow 0.13043478 0.26086957 0.47826087 0.13043478\n\n## using a for loop\nll1 &lt;- 0 ## initialise\nfor(i in 2:n){\n  lli &lt;- log(tm[chain[i-1], chain[i]]) ## element of tm\n  ll1 &lt;- ll1 + lli\n}\nll1 ## log likelihood assuming a first-order Markov chain\n\n[1] -99.9088\n\n## we can benchmark using the markovchain package \nmarkovchain::markovchainFit(data = first_leg, method = \"mle\")$logLikelihood\n\n[1] -99.9088\n\n\nConstruction a likelihood ratio test statistic\n\\[\\Lambda = 2 \\left( \\log(L_1(p;x_t|x_{t-1}))  - \\log(L_0(p; x)) \\right)\\]\nUnder the NULL hypothesis \\(H_0\\), the test statistic \\(\\Lambda\\) asymptotically follows a \\(\\chi^2\\) distribution with degrees of freedom \\(\\text{df} = (k - 1)^2\\).\nIn R\n\ndelta &lt;- 2 * (ll1 - ll0)\ndf &lt;- (k - 1)^2\np_val &lt;- pchisq(delta, df, lower.tail = FALSE)\n\nNo evidence against the outfits being independent.\n\n\n\n\n\nDistribution of the test statistic under the NULL hypothesis, the observed value shown in purple.\n\n\n\n\nSo, let’s make a function.\n\nlrt &lt;- function(x, plot = FALSE){\n  ## under H0\n  n &lt;- length(x)\n  k &lt;- length(unique(x))\n  chain &lt;- as.factor(x)\n  p_indep &lt;- table(chain) / n\n  ll0 &lt;- p_indep[as.integer(chain)] |&gt; log() |&gt; sum() \n  ## first-order Markov\n  tm &lt;- prop.table(transitions(x), 1) \n  ll1 &lt;- 0 \n  for(i in 2:n){\n    lli &lt;- log(tm[chain[i-1], chain[i]]) \n    ll1 &lt;- ll1 + lli\n  }\n  ## test statistic\n  delta &lt;- 2 * (ll1 - ll0)\n  df &lt;- (k - 1)^2\n  p_val &lt;- pchisq(delta, df, lower.tail = FALSE)\n  if(plot){\n    chi &lt;- data.frame(x = seq(0, 30, length.out = 100))\n    chi$density &lt;- dchisq(chi$x, df = df)\n    chi %&gt;%\n      ggplot(aes(x = x, y = density)) +\n      geom_line(linewidth = 2) +\n      geom_vline(aes(xintercept = delta), linetype = \"dashed\", colour = \"purple\") +\n      labs(title = \"\",x = \"\", y = \"\") + theme_bw() -&gt; p\n    print(p)\n  }\n  ## info to return\n  return(list(\"ll0\" = ll0,\n              \"ll1\" = ll1,\n              \"delta\" = delta,\n              \"df\" = df,\n              \"p.val\" = p_val))\n}\n\nlrt(first_leg)\n\n$ll0\n[1] -106.4928\n\n$ll1\n[1] -99.9088\n\n$delta\n[1] 13.16793\n\n$df\n[1] 9\n\n$p.val\n[1] 0.1551535\n\nlrt(mid_leg, plot = TRUE)\n\n\n\n\n$ll0\n[1] -52.30575\n\n$ll1\n[1] -39.26825\n\n$delta\n[1] 26.075\n\n$df\n[1] 4\n\n$p.val\n[1] 3.056156e-05\n\nlrt(final_leg, plot = TRUE)\n\n\n\n\n$ll0\n[1] -26.26847\n\n$ll1\n[1] -14.04639\n\n$delta\n[1] 24.44415\n\n$df\n[1] 16\n\n$p.val\n[1] 0.08024261\n\n\nFirst order Markov chain?\nSo, might we believe that for the European leg of her tour Swift’s outfits weren’t random and perhaps what she wore one night depended on her outfit the previous night (i.e., in stats speak followed a first-order Markov chain)?\n\n\n\n\n\n\nNote\n\n\n\nBasically, the first-order Markov property is that the future state of a system depends only on its current state and is independent of its past history.\n\n\n\nrequire(markovchain)\nverifyMarkovProperty(mid_leg) ## no evidence against the Markov property p-value 0.834 (~likely a Markov chain?)\n\nTesting markovianity property on given data sequence\nChi - square statistic is: 7.339583 \nDegrees of freedom are: 12 \nAnd corresponding p-value is: 0.8343811 \n\nmarkovchainFit(data = mid_leg, method = \"mle\") ## as above but with ses :)\n\n$estimate\nMLE Fit \n A  3 - dimensional discrete Markov Chain defined by the following states: \n Flamingo pink, Ocean blue, Sunset orange \n The transition matrix  (by rows)  is defined as follows: \n              Flamingo pink Ocean blue Sunset orange\nFlamingo pink    0.06666667  0.2666667     0.6666667\nOcean blue       0.57142857  0.0000000     0.4285714\nSunset orange    0.27777778  0.5555556     0.1666667\n\n\n$standardError\n              Flamingo pink Ocean blue Sunset orange\nFlamingo pink    0.06666667  0.1333333    0.21081851\nOcean blue       0.20203051  0.0000000    0.17496355\nSunset orange    0.12422600  0.1756821    0.09622504\n\n$confidenceLevel\n[1] 0.95\n\n$lowerEndpointMatrix\n              Flamingo pink  Ocean blue Sunset orange\nFlamingo pink    0.00000000 0.005338081    0.25346989\nOcean blue       0.17545597 0.000000000    0.08564909\nSunset orange    0.03429924 0.211224910    0.00000000\n\n$upperEndpointMatrix\n              Flamingo pink Ocean blue Sunset orange\nFlamingo pink     0.1973310  0.5279953     1.0000000\nOcean blue        0.9674012  0.0000000     0.7714938\nSunset orange     0.5212563  0.8998862     0.3552643\n\n$logLikelihood\n[1] -39.26825\n\n\nWhat about 1st vs 2nd Markov Chain\n\n## Let's trick markovchain into doing this for us\n## by creating a \"first order\" chain which is actually of order 2\n\nsnap &lt;- data.frame(current = mid_leg)\nsnap$future &lt;- lead(snap$current, 1)\nsnap$past &lt;- lag(snap$current, 1)\n\nsec_order &lt;- snap |&gt;\n  filter(!is.na(future) & !is.na(past)) %&gt;%\n  tidyr::unite(\"y_current\", c(\"past\", \"current\"), remove = FALSE) |&gt;\n  mutate(y_next = lead(y_current, 1),\n         y_previous = lag(y_current, 1))\n\nll1 &lt;- markovchainFit(data = mid_leg, method = \"mle\")$logLikelihood\nll1\n\n[1] -39.26825\n\nll2 &lt;- markovchainFit(data = sec_order$y_current, method = \"mle\")$logLikelihood\nll2 ## eyeballing this, looks pretty similar to 1st order\n\n[1] -32.29189\n\n\nFor fun let’s also calculate the 2nd order Markov Chain likelihood manually.\n\n## function to calculate the log likelihood assuming a second-order Markov chain\nll2 &lt;- function(x){\n  n &lt;- length(x)\n  k &lt;- length(unique(x))\n  chain &lt;- as.factor(x)\n  ## Initialize 3D transition count array\n  counts &lt;- array(0, dim = c(k, k, k))\n  int &lt;- as.integer(chain)\n  for (t in 3:n) {\n    a &lt;- int[t - 2]\n    b &lt;- int[t - 1]\n    c &lt;- int[t]\n    counts[a, b, c] &lt;- counts[a, b, c] + 1\n    }\n  ## Calculate conditional probabilities\n  probs &lt;- counts\n  for (a in 1:k) {\n    for (b in 1:k) {\n      total &lt;- sum(counts[a, b, ])\n    if (total &gt; 0) {probs[a, b, ] &lt;- counts[a, b, ] / total}\n      }\n    }\n  ll &lt;- 0\n  for (t in 3:n) {\n    a &lt;- int[t - 2]\n    b &lt;- int[t - 1]\n    c &lt;- int[t]\n    p &lt;- probs[a, b, c]\n    if (p &gt; 0) {ll &lt;- ll + log(p)}\n  }\n  return(ll)\n}\n## 2nd order Markov Chain log-likelihood\nll2(mid_leg)\n\n[1] -32.88436"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Colours of the Taylor Swift Universe",
    "section": "",
    "text": "Screaming Colours: A Swiftie Guide to Eras Tour Stats\nA short collection of visualization and Rstats exercises exploring Taylor Swift’s use of colour in her Eras tour outfits and her lyrics!\nThis whole analysis started with a Swiftie curiosity over the selection of surprise songs’ dresses colours and if they reflected the mood being sang in said songs. This then raised the question of which possible meaning that colours might have in the Swiftverse. Where do we even start analyzing that?\nWhat followed was months of metadata being added to songs; identifying every single time Swift mentions colour and what they mean (it turns out, 45% of her songs mention colour!); decision over which package to use to tokenize song’s moods and rate them on a scale of most negative to most positive; which led to another question: would lore collected by a long-time fan be more meaningful to identify the song’s meaning over an automated dictionary-based approach?\nOne might say this Swiftie fell in a rabbit hole, or is walking down Clown-elia Street again, but with Eras Tour ending and no signal of Debut (TV) or Reputation (TV) being released, there was some considerable amount of time that could be dedicated to this silly and fun passion project. 🤓\nRather than Rstats if you’d simply like to make a Taylor Swift playlist based on sentiment, colours and/or muses then have a play with our Screaming Colour Taylor Swift Playlist Generator!\n\n\n\nSome r/TaylorSwift reading if you’re keen\n\nRepetition in Taylor Swift Discography\nSnakegate timeline\nWhat would Taylor discography be like if snakegate didn’t happen?"
  },
  {
    "objectID": "viz.html#we-never-go-out-of-style-the-most-worn-looks",
    "href": "viz.html#we-never-go-out-of-style-the-most-worn-looks",
    "title": "2  Visualizing the data",
    "section": "We Never Go Out of Style: The most worn looks",
    "text": "We Never Go Out of Style: The most worn looks\nLooking at it now, it all seems so simple: the addition of new dresses across the tour legs brought more diversity in the colour spectrum of the surprise songs setlist, although the original colours were still the most predominant among them all.\nLooking at the plot, we can see Pink dominates the spectrum, accounting for nearly 20% of all surprise song performances. Yellow follows at 15.6%, with Green and Sunset Orange tied at 13.6% each. The least common colours—Popsicle, Cotton Candy, and Grapefruit—make rare but memorable appearances at just 2-3% each.\n\n\nCode\n## map hex colour to outfit\ndresscolourMapping &lt;- unique(surpriseSongsDressColours %&gt;% select(DressName, ColourHex1))\ncolourPaletteDresses &lt;- setNames(dresscolourMapping$ColourHex1, dresscolourMapping$DressName)\npathToDressColours &lt;- \"dress_images/images_no_background/\"\n## map outfits to the corresponding images\noneRowPerConcert %&gt;%\n    count(DressName) %&gt;%\n    mutate(\n        percentage = n / sum(n) * 100,\n        imagePath = case_when(\n            DressName == \"Pink\" ~paste0(pathToDressColours, \"Pink.png\"),\n            DressName == \"Green\" ~paste0(pathToDressColours, \"Green.png\"),\n            DressName == \"Yellow\" ~paste0(pathToDressColours, \"Yellow.png\"),\n            DressName == \"Blue\" ~paste0(pathToDressColours, \"Blue.png\"),\n            DressName == \"Flamingo pink\" ~ paste0(pathToDressColours,\"Flamingo Pink.png\"),\n            DressName == \"Ocean blue\" ~ paste0(pathToDressColours,\"Ocean Blue.png\"),\n            DressName == \"Sunset orange\" ~ paste0(pathToDressColours,\"Sunset Orange.png\"),\n            DressName == \"Cotton candy\" ~paste0(pathToDressColours, \"Cotton Candy.png\"),\n            DressName == \"Blurple\" ~paste0(pathToDressColours, \"Blurple.png\"),\n            DressName == \"Grapefruit\" ~ paste0(pathToDressColours,\"Grapefruit.png\"),\n            DressName == \"Popsicle\" ~ paste0(pathToDressColours,\"Popsicle.png\"),\n            TRUE ~ NA_character_\n        )) -&gt; outfits\n\n## barchart\nggplot(outfits, aes(x = reorder(DressName, -n), y = n, fill = DressName)) +\n    geom_bar(stat = \"identity\", width = 0.8) +  \n    geom_image(\n        aes(image = imagePath, y = n),  \n        size = 0.15,                    \n        by = \"height\"                    \n    ) +\n    geom_text(\n        aes(y = n + 3.8, label = paste0(n, \"\\n(\", round(percentage, 1), \"%)\")),  \n        vjust = 0,  \n        colour = \"black\",\n        size = 4\n    ) +\n    scale_fill_manual(values = colourPaletteDresses) +\n    theme_minimal() +\n    labs(title = \"\", x = \"\", y = \"\") +\n    theme(\n        axis.text.x = element_text(angle = 45, hjust = 1, size = 14),\n        axis.text.y = element_text(size = 14),\n        plot.title = element_text(hjust = 0.5, size = 16),\n        axis.title.x = element_blank(),\n        axis.title.y = element_blank(),\n        legend.position = \"none\"\n    ) + ylim(0, 35)"
  },
  {
    "objectID": "viz.html#you-belong-with-me-surprise-song-color-groups",
    "href": "viz.html#you-belong-with-me-surprise-song-color-groups",
    "title": "2  Visualizing the data",
    "section": "You Belong With Me: Surprise song color groups",
    "text": "You Belong With Me: Surprise song color groups\nThroughout the Eras Tour, we identified twenty-two (Ooh) surprise songs that were always performed with the same colour family. The blue family (including Blue and Ocean Blue) became the emotional home for reflective, vulnerable tracks like New Year’s Day, Sweet Nothing, and Dear Reader.\nMeanwhile, the red spectrum (including Pink and Flamingo Pink) claimed passionate, confident anthems like I Think He Knows, Tell Me Why, and Dear John.\nThe vibrant yellow family (including Yellow and Sunset Orange) became the consistent backdrop for energetic, resilience-themed tracks like Slut! and I Can Fix Him (No Really I Can).\n\n\nCode\nsurpriseSongsDressColours$groupName &lt;- sapply(surpriseSongsDressColours$DressName, function(color) {\n  if (color %in% c(\"Pink\", \"Flamingo pink\")) return(\"reds\")\n  if (color %in% c(\"Green\")) return(\"greens\")\n  if(color %in% c(\"Yellow\", \"Sunset orange\")) return(\"yellows\")\n  if (color %in% c(\"Ocean blue\", \"Blue\")) return (\"blues\")\n  if (color %in% c(\"Popsicle\", \"Cotton candy\", \"Grapefruit\")) return (\"colorful\")\n  return(\"Neutral\")\n})\n\nsongs_with_single_color_group &lt;- surpriseSongsDressColours %&gt;%\n  group_by(`Song title`) %&gt;%\n  summarize(\n    total_performances = n(),\n    unique_color_groups = n_distinct(groupName),\n    color_group = first(groupName) \n  ) %&gt;%\n  filter(unique_color_groups == 1, total_performances &gt; 1) %&gt;%\n  arrange(desc(total_performances))\n\nsingle_color_performances &lt;- surpriseSongsDressColours %&gt;%\n    filter(`Song title` %in% songs_with_single_color_group$`Song title`)\n\n## pics\nblues &lt;- paste(\"dress_images/images_no_background/\", c(\"Blue\", \"Ocean Blue\"), \".png\", sep = \"\")\nreds &lt;- paste(\"dress_images/images_no_background/\", c(\"Pink\", \"Flamingo Pink\"), \".png\", sep = \"\")\nyellows &lt;- paste(\"dress_images/images_no_background/\", c(\"Yellow\", \"Sunset Orange\"), \".png\", sep = \"\")\n\ncoords &lt;- circleProgressiveLayout(table(single_color_performances$groupName),\n                                  sizetype = 'area')\ncoords$id &lt;- names(table(single_color_performances$groupName))\ndf.gg &lt;- circleLayoutVertices(coords, npoints = 8, id = 4)\nsnames &lt;- single_color_performances %&gt;% select('Song title', groupName) %&gt;%\n    group_by(`Song title`) %&gt;% mutate(count = n()) %&gt;% ungroup() |&gt; unique()\nset.seed(1984) ## for jitter repel\nplot &lt;- ggplot() + theme_void() +\n    ## blues\n    geom_polygon(data = df.gg[df.gg$id == \"blues\",], aes(x = x, y = y),\n                 fill = \"#0000FF\", alpha = 0.05) +\n    geom_text_repel(aes(x = coords$x[1], \n                        y = coords$y[1], \n                        label = snames$`Song title`[snames$groupName == \"blues\"]),\n                    col = \"#0000FF\", nudge_y = -1.1, nudge_x = 0.1, segment.color = NA,\n                    size = 1.5*snames$count[snames$groupName == \"blues\"], box.padding = 0.1) +\n    ## reds\n    geom_polygon(data = df.gg[df.gg$id == \"reds\",], aes(x = x, y = y),\n                 fill = \"#FF0000\", alpha = 0.05)  +\n    geom_text_repel(aes(x = coords$x[2], \n                        y = coords$y[2], \n                        label = snames$`Song title`[snames$groupName == \"reds\"]),\n                    col = \"#FF0000\", nudge_y = -0.9, nudge_x = 0.1, segment.color = NA,\n                    size = 1.5*snames$count[snames$groupName == \"reds\"], box.padding = 0.1) +\n    ## yellows\n    geom_polygon(data = df.gg[df.gg$id == \"yellows\",], aes(x = x, y = y),\n                 fill = \"#FFBF00\", alpha = 0.05)  +\n    geom_text_repel(aes(x = coords$x[3], \n                        y = coords$y[3], \n                        label = snames$`Song title`[snames$groupName == \"yellows\"]),\n                    col = \"#FFBF00\", nudge_y = 1.4, nudge_x = 0, segment.color = NA,\n                    size = 1.5*snames$count[snames$groupName == \"yellows\"], box.padding = 0.1)\n\n## image sizes relative to\n## table(single_color_performances$DressName, single_color_performances$groupName)\nset.seed(1984) ## for jitter repel\nggdraw() +\n    draw_plot(plot) +\n    draw_image(blues[1], -0.37, 0.23, scale = 0.7/3) +\n    draw_image(blues[2],  -0.2, 0.32, scale = 0.9/3) +\n    #draw_image(blues[3],  -0.07, 0.26, scale = 0.4/3) +\n    draw_image(reds[1], 0.1, 0.27, scale = 0.8/3) +\n    draw_image(reds[2],  0.3, 0.33, scale = 0.7/3) +\n    draw_image(yellows[1], -0.1, -0.25, scale = 0.7/3) +\n    draw_image(yellows[2],  0.1, -0.3, scale = 1.1/3)"
  },
  {
    "objectID": "viz.html#you-belong-with-me-surprise-song-colour-groups",
    "href": "viz.html#you-belong-with-me-surprise-song-colour-groups",
    "title": "2  Visualizing the data",
    "section": "You Belong With Me: Surprise song colour groups",
    "text": "You Belong With Me: Surprise song colour groups\nThroughout the Eras Tour, we identified twenty-two (Ooh) surprise songs that were always performed with the same colour family. The blue family (including Blue and Ocean Blue) became the emotional home for reflective, vulnerable tracks like New Year’s Day, Sweet Nothing, and Dear Reader.\nMeanwhile, the red spectrum (including Pink and Flamingo Pink) claimed passionate, confident anthems like I Think He Knows, Tell Me Why, and Dear John.\nThe vibrant yellow family (including Yellow and Sunset Orange) became the consistent backdrop for energetic, resilience-themed tracks like Slut! and I Can Fix Him (No Really I Can).\n\n\nCode\nsurpriseSongsDressColours$groupName &lt;- sapply(surpriseSongsDressColours$DressName, function(colour) {\n  if (colour %in% c(\"Pink\", \"Flamingo pink\")) return(\"reds\")\n  if (colour %in% c(\"Green\")) return(\"greens\")\n  if(colour %in% c(\"Yellow\", \"Sunset orange\")) return(\"yellows\")\n  if (colour %in% c(\"Ocean blue\", \"Blue\")) return (\"blues\")\n  if (colour %in% c(\"Popsicle\", \"Cotton candy\", \"Grapefruit\")) return (\"colourful\")\n  return(\"Neutral\")\n})\n\nsongs_with_single_colour_group &lt;- surpriseSongsDressColours %&gt;%\n  group_by(`Song title`) %&gt;%\n  summarize(\n    total_performances = n(),\n    unique_colour_groups = n_distinct(groupName),\n    colour_group = first(groupName) \n  ) %&gt;%\n  filter(unique_colour_groups == 1, total_performances &gt; 1) %&gt;%\n  arrange(desc(total_performances))\n\nsingle_colour_performances &lt;- surpriseSongsDressColours %&gt;%\n    filter(`Song title` %in% songs_with_single_colour_group$`Song title`)\n\n## pics\nblues &lt;- paste(\"dress_images/images_no_background/\", c(\"Blue\", \"Ocean Blue\"), \".png\", sep = \"\")\nreds &lt;- paste(\"dress_images/images_no_background/\", c(\"Pink\", \"Flamingo Pink\"), \".png\", sep = \"\")\nyellows &lt;- paste(\"dress_images/images_no_background/\", c(\"Yellow\", \"Sunset Orange\"), \".png\", sep = \"\")\n\ncoords &lt;- circleProgressiveLayout(table(single_colour_performances$groupName),\n                                  sizetype = 'area')\ncoords$id &lt;- names(table(single_colour_performances$groupName))\ndf.gg &lt;- circleLayoutVertices(coords, npoints = 8, id = 4)\nsnames &lt;- single_colour_performances %&gt;% select('Song title', groupName) %&gt;%\n    group_by(`Song title`) %&gt;% mutate(count = n()) %&gt;% ungroup() |&gt; unique()\nset.seed(1984) ## for jitter repel\nplot &lt;- ggplot() + theme_void() +\n    ## blues\n    geom_polygon(data = df.gg[df.gg$id == \"blues\",], aes(x = x, y = y),\n                 fill = \"#0000FF\", alpha = 0.05) +\n    geom_text_repel(aes(x = coords$x[1], \n                        y = coords$y[1], \n                        label = snames$`Song title`[snames$groupName == \"blues\"]),\n                    col = \"#0000FF\", nudge_y = -1.1, nudge_x = 0.1, segment.colour = NA,\n                    size = 1.5*snames$count[snames$groupName == \"blues\"], box.padding = 0.1) +\n    ## reds\n    geom_polygon(data = df.gg[df.gg$id == \"reds\",], aes(x = x, y = y),\n                 fill = \"#FF0000\", alpha = 0.05)  +\n    geom_text_repel(aes(x = coords$x[2], \n                        y = coords$y[2], \n                        label = snames$`Song title`[snames$groupName == \"reds\"]),\n                    col = \"#FF0000\", nudge_y = -0.9, nudge_x = 0.1, segment.colour = NA,\n                    size = 1.5*snames$count[snames$groupName == \"reds\"], box.padding = 0.1) +\n    ## yellows\n    geom_polygon(data = df.gg[df.gg$id == \"yellows\",], aes(x = x, y = y),\n                 fill = \"#FFBF00\", alpha = 0.05)  +\n    geom_text_repel(aes(x = coords$x[3], \n                        y = coords$y[3], \n                        label = snames$`Song title`[snames$groupName == \"yellows\"]),\n                    col = \"#FFBF00\", nudge_y = 1.4, nudge_x = 0, segment.colour = NA,\n                    size = 1.5*snames$count[snames$groupName == \"yellows\"], box.padding = 0.1)\n\n## image sizes relative to\n## table(single_colour_performances$DressName, single_colour_performances$groupName)\nset.seed(1984) ## for jitter repel\nggdraw() +\n    draw_plot(plot) +\n    draw_image(blues[1], -0.37, 0.23, scale = 0.7/3) +\n    draw_image(blues[2],  -0.2, 0.32, scale = 0.9/3) +\n    #draw_image(blues[3],  -0.07, 0.26, scale = 0.4/3) +\n    draw_image(reds[1], 0.1, 0.27, scale = 0.8/3) +\n    draw_image(reds[2],  0.3, 0.33, scale = 0.7/3) +\n    draw_image(yellows[1], -0.1, -0.25, scale = 0.7/3) +\n    draw_image(yellows[2],  0.1, -0.3, scale = 1.1/3)"
  }
]